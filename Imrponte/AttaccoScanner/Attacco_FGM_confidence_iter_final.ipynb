{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attacco_FGM_confidence_iter_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lcoLiAGAtqBh",
        "OHENSlCXxzcr",
        "nGmEBN4oxqUO",
        "pIqUXUmoA541",
        "-ycpjmyb4Cxe",
        "dherpFOH0Uau",
        "5X10jetEyAax",
        "fETy1V2abbWo",
        "VeQuyOYGbbWp",
        "_miDmRukbbWq",
        "I5sK56TG2eT9",
        "9XepXK-ny3XN",
        "PBSyijWDqY4-",
        "O_c2L3v0r2xG",
        "VRhT4XM1sVm-",
        "MAU1QYvhrGVs",
        "aVwvG_5SKo7x",
        "xRRSYT01GRfB",
        "P3kr1yAn2UBl",
        "-56wdwb5TLHl",
        "QCO-pkW9GXc0",
        "kJ6xDO5GGZY5",
        "y71Fo3alJY0s",
        "nkdhgkab0e-B",
        "O2z5CDqCOjhi",
        "iTIkMx6Evczx",
        "liAmXvKByROm",
        "OzZkC7HimlHT",
        "Suibji7V0I7j",
        "Fq6B6unj2HcX",
        "cYPmQSaL2Oxa",
        "8w98YNCQGJGq",
        "ZFKEoI-enb8L",
        "g_sQeKbZfK74",
        "nLcnge6A0Npi",
        "lqk0NmxqjXkm",
        "Rn8n_-yejatQ"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37577c7a43f041e78086869c4df65e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9218f5a725ad431cbd31cc9f6baf556b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_55fd440b7b624e9d8b959230d1fe6d8b",
              "IPY_MODEL_444ea8f92ca04d0d8ace4c9677786991",
              "IPY_MODEL_d40f63aee71f432ea9c466c406953cfe"
            ]
          }
        },
        "9218f5a725ad431cbd31cc9f6baf556b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55fd440b7b624e9d8b959230d1fe6d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_432c24dacaf84bfd9e8d0f4ce9654b44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_275e5a3296df44d399f14e9e37879c3b"
          }
        },
        "444ea8f92ca04d0d8ace4c9677786991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8706711c71544adba22745c58a25aafe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c6144ca51524456af62d80279219a12"
          }
        },
        "d40f63aee71f432ea9c466c406953cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d7bf558e6bbe4b078584308b7f774f8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:03&lt;00:00, 183MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c888579db6134d6ea67cc527275bf263"
          }
        },
        "432c24dacaf84bfd9e8d0f4ce9654b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "275e5a3296df44d399f14e9e37879c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8706711c71544adba22745c58a25aafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c6144ca51524456af62d80279219a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7bf558e6bbe4b078584308b7f774f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c888579db6134d6ea67cc527275bf263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/Tesi/blob/main/Imrponte/AttaccoScanner/Attacco_FGM_confidence_iter_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoLiAGAtqBh"
      },
      "source": [
        "# **Init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHENSlCXxzcr"
      },
      "source": [
        "##Import ART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKN5Oqa-i6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de07d47b-0d5d-49bf-9add-563d4a04e73e"
      },
      "source": [
        "#importa ART\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.8.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 768 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 798 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 880 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 890 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 911 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 921 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 942 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 952 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 972 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 983 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Collecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 81.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.0.1)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.8.1 llvmlite-0.37.0 numba-0.54.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "## Import librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RXI-DDIb3C"
      },
      "source": [
        "#Librerie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "#import time\n",
        "#import os\n",
        "#import shutil\n",
        "#import copy\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIqUXUmoA541"
      },
      "source": [
        "##Check device\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2pe5Zh2A4Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464dc5e3-4702-468f-b023-7d9da4ef9d18"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n",
            "True\n",
            "Tesla P100-PCIE-16GB\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WApYIVcnU9sq"
      },
      "source": [
        "##Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi_cyTbXU-8s"
      },
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "transf_init=transforms.Resize(size=(1000,1000),interpolation=InterpolationMode.NEAREST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "##Def path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#scanner\n",
        "scanner_name = 'HiScan'\n",
        "\n",
        "#salvataggio modello\n",
        "model_name = 'VGG19_10epoc_lr5_bs200_adam'\n",
        "path_model = F\"/content/gdrive/My Drive/ModelliCNN/Scanner/{scanner_name}/{model_name}\" \n",
        "\n",
        "#dataset\n",
        "pathTestset=F'/content/gdrive/MyDrive/Dataset_impronte/test/{scanner_name}'\n",
        "\n",
        "pd_preds_value=F'/content/gdrive/MyDrive/Dataset_impronte/test/Preds_value/{scanner_name}.xlsx'\n",
        "\n",
        "data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "##Collegamento google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvTOQw-aHRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690fe534-0f71-4e30-8076-be35a973bee9"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fETy1V2abbWo"
      },
      "source": [
        "##Caricamento dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMW6yAMPbbWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fb4692-87c7-4d6a-a083-94df42eede51"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(pathTestset,transforms.ToTensor())\n",
        "dim_set=len(test_dataset)\n",
        "print(dim_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_miDmRukbbWq"
      },
      "source": [
        "##Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3JB4rWJbbWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d5a436-7094-42ac-88ff-4967ba6386bd"
      },
      "source": [
        "testgen=torch.utils.data.DataLoader(test_dataset, pin_memory=True, batch_size=1,num_workers=2)\n",
        "print(len(testgen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazQQE8ypKP9"
      },
      "source": [
        "##Nomi classi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYk4cr4eo9Ir",
        "outputId": "c10e7f21-66be-4d43-a744-31a890d34a7c"
      },
      "source": [
        "classes_name=test_dataset.classes\n",
        "class_number=len(classes_name)\n",
        "print(classes_name)\n",
        "print(class_number)\n",
        "#del test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Live', 'Spoof']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ_O-UAECNMk"
      },
      "source": [
        "#**Riduzione dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnOEmgNRbbWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f9b455-0537-45e7-fc7d-6779582f3b93"
      },
      "source": [
        "test_dataset.samples=test_dataset.samples[997:1002]\n",
        "test_dataset.targets=test_dataset.targets[997:1002]\n",
        "\n",
        "dim_set=len(test_dataset)\n",
        "print(dim_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XepXK-ny3XN"
      },
      "source": [
        "# **Creazione modello**\n",
        "\n",
        "> non ho bloccato i parametri inferiori e sbloccato quelli del classificatore, vedi se funziona\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSyijWDqY4-"
      },
      "source": [
        "##Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymaBXhaPMvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "37577c7a43f041e78086869c4df65e9e",
            "9218f5a725ad431cbd31cc9f6baf556b",
            "55fd440b7b624e9d8b959230d1fe6d8b",
            "444ea8f92ca04d0d8ace4c9677786991",
            "d40f63aee71f432ea9c466c406953cfe",
            "432c24dacaf84bfd9e8d0f4ce9654b44",
            "275e5a3296df44d399f14e9e37879c3b",
            "8706711c71544adba22745c58a25aafe",
            "6c6144ca51524456af62d80279219a12",
            "d7bf558e6bbe4b078584308b7f774f8a",
            "c888579db6134d6ea67cc527275bf263"
          ]
        },
        "outputId": "e397fd91-e1d8-45b5-b6f2-196967024369"
      },
      "source": [
        "model = models.vgg19(pretrained=True,progress=True)\n",
        "#model = models.densenet201(pretrained=True,progress=True)\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37577c7a43f041e78086869c4df65e9e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_c2L3v0r2xG"
      },
      "source": [
        "##Aggiunta classificatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1qeI3_3qKJJ"
      },
      "source": [
        "model.classifier[6]=nn.Linear(4096,2) #per vgg19\n",
        "#model.classifier=nn.Linear(1920,2) #per densenet201\n",
        "\n",
        "#print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOHqOuTVAMaz"
      },
      "source": [
        "##Load pesi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEXv4tQ3AOi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78974391-7e84-4aeb-cba7-1924a3e0a226"
      },
      "source": [
        "model.load_state_dict(torch.load(path_model))#,map_location=torch.device('cpu')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kr1yAn2UBl"
      },
      "source": [
        "# **Def funzioni**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdO07YuUOFS"
      },
      "source": [
        "##calc size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EAve-4iUPk1"
      },
      "source": [
        "def calc_size(n):\n",
        "  '''\n",
        "  n: int \n",
        "  return: 80% of n\n",
        "  '''\n",
        "  return tuple(int(np.ceil(i * (80/100))) for i in n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6xDO5GGZY5"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xth1SmbAne7T"
      },
      "source": [
        "con media senza datframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VvGULk0ng1S"
      },
      "source": [
        "def test_average_preds(classifier,test_loader,):\n",
        "  '''\n",
        "  model: model trained\n",
        "  test_loader: dataloader \n",
        "  return: dataframe{n_img,class_predicted,class_real}\n",
        "  '''\n",
        "  preds=[]\n",
        "  #value=[]\n",
        "  prob=nn.Softmax()\n",
        "  data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])\n",
        "  i=0\n",
        "  for input,label in test_loader:\n",
        "    i+=1\n",
        "    input=transf_init(input) #resize 1000\n",
        "    n=input.shape\n",
        "    n_mod=calc_size(n[2:4])\n",
        "    crop_transform=transforms.TenCrop((n_mod[0],n_mod[1]))\n",
        "    crops=crop_transform(input)\n",
        "    live=0\n",
        "    spoof=0\n",
        "    for crop in crops:\n",
        "      crop=data_transform_test(crop) #resize 224\n",
        "      outputs = classifier.predict(crop)\n",
        "      live+=outputs[0][0]\n",
        "      spoof+=outputs[0][1]\n",
        "    live=live/10\n",
        "    spoof=spoof/10\n",
        "    predicted=np.argmax([live,spoof])\n",
        "    preds.append(predicted)\n",
        "    #value.append(np.max(prob(torch.Tensor([live,spoof])).numpy()))\n",
        "    value=np.max(prob(torch.Tensor([live,spoof])).numpy())\n",
        "\n",
        "  return np.array(preds),value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVSi44LIk0TX"
      },
      "source": [
        "##Array to dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YarvS4XUk2Ka"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def array2dataloader(x,y):\n",
        "  '''\n",
        "  :param x: ndarray x_test;\n",
        "  :param y: labels\n",
        "  '''\n",
        "  tensor_x = torch.Tensor(x) # transform to torch tensor\n",
        "  tensor_y = torch.Tensor(np.argmax(y,axis=1))\n",
        "\n",
        "  my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "  return DataLoader(my_dataset) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfEnYI_UUEb6"
      },
      "source": [
        "##FGM mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3oRorbFUCF-"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import logging\n",
        "from typing import Optional, Union, TYPE_CHECKING\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from art.config import ART_NUMPY_DTYPE\n",
        "from art.attacks.attack import EvasionAttack\n",
        "from art.estimators.estimator import BaseEstimator, LossGradientsMixin\n",
        "from art.estimators.classification.classifier import ClassifierMixin\n",
        "from art.utils import (\n",
        "    compute_success,\n",
        "    get_labels_np_array,\n",
        "    random_sphere,\n",
        "    projection,\n",
        "    check_and_transform_label_format,\n",
        ")\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from art.utils import CLASSIFIER_LOSS_GRADIENTS_TYPE\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class FastGradientMethod_mod(EvasionAttack):\n",
        "    \"\"\"\n",
        "    This attack was originally implemented by Goodfellow et al. (2015) with the infinity norm (and is known as the \"Fast\n",
        "    Gradient Sign Method\"). This implementation extends the attack to other norms, and is therefore called the Fast\n",
        "    Gradient Method.\n",
        "    | Paper link: https://arxiv.org/abs/1412.6572\n",
        "    \"\"\"\n",
        "\n",
        "    attack_params = EvasionAttack.attack_params + [\n",
        "        \"norm\",\n",
        "        \"eps\",\n",
        "        \"eps_step\",\n",
        "        \"targeted\",\n",
        "        \"num_random_init\",\n",
        "        \"batch_size\",\n",
        "        \"minimal\",\n",
        "        \"tensor_board\",\n",
        "    ]\n",
        "    _estimator_requirements = (BaseEstimator, LossGradientsMixin)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        estimator: \"CLASSIFIER_LOSS_GRADIENTS_TYPE\",\n",
        "        norm: Union[int, float, str] = np.inf,\n",
        "        eps: Union[int, float, np.ndarray] = 0.3,\n",
        "        eps_step: Union[int, float, np.ndarray] = 0.1,\n",
        "        targeted: bool = False,\n",
        "        num_random_init: int = 0,\n",
        "        batch_size: int = 32,\n",
        "        minimal: bool = False,\n",
        "        tensor_board: Union[str, bool] = False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Create a :class:`.FastGradientMethod` instance.\n",
        "        :param estimator: A trained classifier.\n",
        "        :param norm: The norm of the adversarial perturbation. Possible values: \"inf\", np.inf, 1 or 2.\n",
        "        :param eps: Attack step size (input variation).\n",
        "        :param eps_step: Step size of input variation for minimal perturbation computation.\n",
        "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False)\n",
        "        :param num_random_init: Number of random initialisations within the epsilon ball. For random_init=0 starting at\n",
        "            the original input.\n",
        "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
        "        :param minimal: Indicates if computing the minimal perturbation (True). If True, also define `eps_step` for\n",
        "                        the step size and eps for the maximum perturbation.\n",
        "        :param tensor_board: Activate summary writer for TensorBoard: Default is `False` and deactivated summary writer.\n",
        "                             If `True` save runs/CURRENT_DATETIME_HOSTNAME in current directory. Provide `path` in type\n",
        "                             `str` to save in path/CURRENT_DATETIME_HOSTNAME.\n",
        "                             Use hierarchical folder structure to compare between runs easily. e.g. pass in ‘runs/exp1’,\n",
        "                             ‘runs/exp2’, etc. for each new experiment to compare across them.\n",
        "        \"\"\"\n",
        "        super().__init__(estimator=estimator, tensor_board=tensor_board)\n",
        "        self.norm = norm\n",
        "        self.eps = eps\n",
        "        self.eps_step = eps_step\n",
        "        self._targeted = targeted\n",
        "        self.num_random_init = num_random_init\n",
        "        self.batch_size = batch_size\n",
        "        self.minimal = minimal\n",
        "        self._project = True\n",
        "        FastGradientMethod_mod._check_params(self)\n",
        "\n",
        "        self._batch_id = 0\n",
        "        self._i_max_iter = 0\n",
        "\n",
        "    def _check_compatibility_input_and_eps(self, x: np.ndarray):\n",
        "        \"\"\"\n",
        "        Check the compatibility of the input with `eps` and `eps_step` which are of the same shape.\n",
        "        :param x: An array with the original inputs.\n",
        "        \"\"\"\n",
        "        if isinstance(self.eps, np.ndarray):\n",
        "            # Ensure the eps array is broadcastable\n",
        "            if self.eps.ndim > x.ndim:\n",
        "                raise ValueError(\"The `eps` shape must be broadcastable to input shape.\")\n",
        "\n",
        "    def _minimal_perturbation(self, x: np.ndarray, y: np.ndarray, target, class_target, max_iter, confidence, mask: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Iteratively compute the minimal perturbation necessary to make the class prediction change. Stop when the\n",
        "        first adversarial example was found.\n",
        "        :param x: An array with the original inputs.\n",
        "        :param y: Target values (class labels) one-hot-encoded of shape (nb_samples, nb_classes).\n",
        "        :param target: targeted attack (mirato a far predire una specifica classe)\n",
        "        :param class_target: class da predire se target=True (nel nostro caso vogliamo far predire sempre live)\n",
        "        :return: An array holding the adversarial examples.\n",
        "        \"\"\"\n",
        "        adv_x = x.copy()\n",
        "        \n",
        "        n_batch=int(np.ceil(adv_x.shape[0] / float(self.batch_size)))\n",
        "        # Compute perturbation with implicit batching\n",
        "        for batch_id in range(n_batch):\n",
        "            batch_index_1, batch_index_2 = (\n",
        "                batch_id * self.batch_size,\n",
        "                (batch_id + 1) * self.batch_size,\n",
        "            )\n",
        "            batch = adv_x[batch_index_1:batch_index_2]\n",
        "            batch_labels = y[batch_index_1:batch_index_2]\n",
        "\n",
        "            #sys.stdout.write(\"\\rBatch {0}/{1}\".format(batch_id,n_batch))\n",
        "            #sys.stdout.flush()\n",
        "\n",
        "            mask_batch = mask\n",
        "            if mask is not None:\n",
        "                # Here we need to make a distinction: if the masks are different for each input, we need to index\n",
        "                # those for the current batch. Otherwise (i.e. mask is meant to be broadcasted), keep it as it is.\n",
        "                if len(mask.shape) == len(x.shape):\n",
        "                    mask_batch = mask[batch_index_1:batch_index_2]\n",
        "\n",
        "            \n",
        "\n",
        "            if target:\n",
        "              #print(\"mod\")\n",
        "              #print(\"class_target \"+str(class_target))\n",
        "              \n",
        "              preds,value=test_average_preds(self.estimator,array2dataloader(batch,batch_labels))\n",
        "              if ((preds==np.argmax(batch_labels, axis=1)) and (preds!= class_target)):\n",
        "                #print(\"preds=label e preds=spoof\")\n",
        "                active_indices=True\n",
        "              elif ((preds!=np.argmax(batch_labels, axis=1)) and (preds== class_target) and (value<confidence)): \n",
        "                #print(\"preds=label, preds=live e confidence<0.6\")\n",
        "                active_indices=True\n",
        "              else:  active_indices=False\n",
        "              #active_indices=np.where(((preds==np.argmax(batch_labels, axis=1)) and (preds!= class_target)) or ((preds!=np.argmax(batch_labels, axis=1)) and (preds== class_target) and (value>confidence)))[0]\n",
        "              \n",
        "              #print(\"labels \"+str(np.argmax(batch_labels, axis=1)))\n",
        "              #print(\"preds: \"+str(preds))\n",
        "              #print(\"active: \"+str(active_indices))\n",
        "            else:\n",
        "              # Get current predictions\n",
        "              np.where(np.argmax(batch_labels, axis=1) == preds )[0]\n",
        "            \n",
        "            if isinstance(self.eps, np.ndarray) and isinstance(self.eps_step, np.ndarray):\n",
        "                if len(self.eps.shape) == len(x.shape) and self.eps.shape[0] == x.shape[0]:\n",
        "                    current_eps = self.eps_step[batch_index_1:batch_index_2]\n",
        "                    partial_stop_condition = (current_eps <= self.eps[batch_index_1:batch_index_2]).all()\n",
        "\n",
        "                else:\n",
        "                    current_eps = self.eps_step\n",
        "                    partial_stop_condition = (current_eps <= self.eps).all()\n",
        "\n",
        "            else:\n",
        "                current_eps = self.eps_step\n",
        "                partial_stop_condition = current_eps <= self.eps\n",
        "            iter=0\n",
        "            #ridimensionamento per le img spoof spoof\n",
        "            if active_indices==True:\n",
        "              \n",
        "              trans_prova= transforms.Compose([#transforms.ToPILImage(),\n",
        "                                               transforms.Resize([224,224],interpolation=InterpolationMode.NEAREST),\n",
        "                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "                                               #transforms.ToTensor()\n",
        "                ])\n",
        "              batch=trans_prova(torch.Tensor(batch))\n",
        "              batch=np.array(batch.numpy())\n",
        "              \n",
        "            while active_indices==True and partial_stop_condition and iter<max_iter:\n",
        "                iter+=1\n",
        "                #print(\"iter: \"+str(iter))\n",
        "                # Adversarial crafting\n",
        "                # Get perturbation\n",
        "                perturbation = self._compute_perturbation(batch, batch_labels, mask_batch)\n",
        "                current_x = self._apply_perturbation(batch, perturbation, current_eps)\n",
        "\n",
        "                # Update\n",
        "                #batch[active_indices] = current_x[active_indices]\n",
        "                batch = current_x\n",
        "                preds,value=test_average_preds(self.estimator,array2dataloader(batch,batch_labels))\n",
        "                #print(preds,value)\n",
        "                #print(batch_labels)\n",
        "                # If targeted active check to see whether we have hit the target, otherwise head to anything but\n",
        "                if self.targeted:\n",
        "                    active_indices = np.where(np.argmax(batch_labels, axis=1) != np.argmax(preds, axis=1))[0]\n",
        "                else:\n",
        "                    if target:\n",
        "                      if ((preds==np.argmax(batch_labels, axis=1)) and (preds!= class_target)):\n",
        "                        #print(\"preds=label e preds=spoof\")\n",
        "                        active_indices=True\n",
        "                      elif ((preds!=np.argmax(batch_labels, axis=1)) and (preds== class_target) and (value<confidence)): \n",
        "                        #print(\"preds=label, preds=live e confidence<0.6\")\n",
        "                        active_indices=True\n",
        "                      else:  active_indices=False\n",
        "                    else:\n",
        "                      active_indices = np.where(np.argmax(batch_labels, axis=1) == preds )[0]\n",
        "                    #print(\"preds: \"+str(preds))\n",
        "                    #print(\"active_ind: \"+str(active_indices))\n",
        "\n",
        "                # Update current eps and check the stop condition\n",
        "                if isinstance(self.eps, np.ndarray) and isinstance(self.eps_step, np.ndarray):\n",
        "                    if len(self.eps.shape) == len(x.shape) and self.eps.shape[0] == x.shape[0]:\n",
        "                        current_eps = current_eps + self.eps_step[batch_index_1:batch_index_2]\n",
        "                        partial_stop_condition = (current_eps <= self.eps[batch_index_1:batch_index_2]).all()\n",
        "\n",
        "                    else:\n",
        "                        current_eps = current_eps + self.eps_step\n",
        "                        partial_stop_condition = (current_eps <= self.eps).all()\n",
        "\n",
        "                else:\n",
        "                    current_eps = current_eps + self.eps_step\n",
        "                    partial_stop_condition = current_eps <= self.eps\n",
        "\n",
        "            #adv_x[batch_index_1:batch_index_2] = batch\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def generate(self, x: np.ndarray, y: Optional[np.ndarray] = None, target=False, class_target=None, max_iter=10, confidence=0.6, **kwargs) -> np.ndarray:\n",
        "        \"\"\"Generate adversarial samples and return them in an array.\n",
        "        :param x: An array with the original inputs.\n",
        "        :param y: Target values (class labels) one-hot-encoded of shape (nb_samples, nb_classes) or indices of shape\n",
        "                  (nb_samples,). Only provide this parameter if you'd like to use true labels when crafting adversarial\n",
        "                  samples. Otherwise, model predictions are used as labels to avoid the \"label leaking\" effect\n",
        "                  (explained in this paper: https://arxiv.org/abs/1611.01236). Default is `None`.\n",
        "        :param target: indica se l'attacco è mirato a far predire una determinata classe.\n",
        "        :param class_target: se target=True specifica quale classe far predire.\n",
        "        :param max_iter: numero massimo di iterazioni da effettuare su ogni singolo batch nel caso minimal.\n",
        "        :param confidence: indica la probabilità minima con la quale il classificatore deve predire una classe affinché l'attacco si arresti.          \n",
        "        :param mask: An array with a mask broadcastable to input `x` defining where to apply adversarial perturbations.\n",
        "                     Shape needs to be broadcastable to the shape of x and can also be of the same shape as `x`. Any\n",
        "                     features for which the mask is zero will not be adversarially perturbed.\n",
        "        :type mask: `np.ndarray`\n",
        "        :return: An array holding the adversarial examples.\n",
        "        \"\"\"\n",
        "        mask = self._get_mask(x, **kwargs)\n",
        "\n",
        "        # Ensure eps is broadcastable\n",
        "        self._check_compatibility_input_and_eps(x=x)\n",
        "\n",
        "        if isinstance(self.estimator, ClassifierMixin):\n",
        "            y = check_and_transform_label_format(y, self.estimator.nb_classes)\n",
        "\n",
        "            if y is None:\n",
        "                # Throw error if attack is targeted, but no targets are provided\n",
        "                if self.targeted:\n",
        "                    raise ValueError(\"Target labels `y` need to be provided for a targeted attack.\")\n",
        "\n",
        "                # Use model predictions as correct outputs\n",
        "                logger.info(\"Using model predictions as correct labels for FGM.\")\n",
        "                y = get_labels_np_array(self.estimator.predict(x, batch_size=self.batch_size))  # type: ignore\n",
        "\n",
        "            if self.estimator.nb_classes > 2:\n",
        "                y = y / np.sum(y, axis=1, keepdims=True)\n",
        "\n",
        "            # Return adversarial examples computed with minimal perturbation if option is active\n",
        "            rate_best: Optional[float]\n",
        "            if self.minimal:\n",
        "                logger.info(\"Performing minimal perturbation FGM.\")\n",
        "                adv_x_best = self._minimal_perturbation(x, y, target, class_target, max_iter, confidence, mask)\n",
        "                rate_best = 100 * compute_success(\n",
        "                    self.estimator,  # type: ignore\n",
        "                    x,\n",
        "                    y,\n",
        "                    adv_x_best,\n",
        "                    self.targeted,\n",
        "                    batch_size=self.batch_size,  # type: ignore\n",
        "                )\n",
        "            else:\n",
        "                adv_x_best = None\n",
        "                rate_best = None\n",
        "\n",
        "                for _ in range(max(1, self.num_random_init)):\n",
        "                    adv_x = self._compute(\n",
        "                        x,\n",
        "                        x,\n",
        "                        y,\n",
        "                        mask,\n",
        "                        self.eps,\n",
        "                        self.eps,\n",
        "                        self._project,\n",
        "                        self.num_random_init > 0,\n",
        "                    )\n",
        "\n",
        "                    if self.num_random_init > 1:\n",
        "                        rate = 100 * compute_success(\n",
        "                            self.estimator,  # type: ignore\n",
        "                            x,\n",
        "                            y,\n",
        "                            adv_x,\n",
        "                            self.targeted,\n",
        "                            batch_size=self.batch_size,  # type: ignore\n",
        "                        )\n",
        "                        if rate_best is None or rate > rate_best or adv_x_best is None:\n",
        "                            rate_best = rate\n",
        "                            adv_x_best = adv_x\n",
        "                    else:\n",
        "                        adv_x_best = adv_x\n",
        "\n",
        "            logger.info(\n",
        "                \"Success rate of FGM attack: %.2f%%\",\n",
        "                rate_best\n",
        "                if rate_best is not None\n",
        "                else 100\n",
        "                * compute_success(\n",
        "                    self.estimator,  # type: ignore\n",
        "                    x,\n",
        "                    y,\n",
        "                    adv_x_best,\n",
        "                    self.targeted,\n",
        "                    batch_size=self.batch_size,\n",
        "                ),\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            if self.minimal:\n",
        "                raise ValueError(\"Minimal perturbation is only supported for classification.\")\n",
        "\n",
        "            if y is None:\n",
        "                # Throw error if attack is targeted, but no targets are provided\n",
        "                if self.targeted:\n",
        "                    raise ValueError(\"Target labels `y` need to be provided for a targeted attack.\")\n",
        "\n",
        "                # Use model predictions as correct outputs\n",
        "                logger.info(\"Using model predictions as correct labels for FGM.\")\n",
        "                y = self.estimator.predict(x, batch_size=self.batch_size)\n",
        "\n",
        "            adv_x_best = self._compute(\n",
        "                x,\n",
        "                x,\n",
        "                y,\n",
        "                None,\n",
        "                self.eps,\n",
        "                self.eps,\n",
        "                self._project,\n",
        "                self.num_random_init > 0,\n",
        "            )\n",
        "\n",
        "        return adv_x_best\n",
        "\n",
        "    def _check_params(self) -> None:\n",
        "\n",
        "        if self.norm not in [1, 2, np.inf, \"inf\"]:\n",
        "            raise ValueError('Norm order must be either 1, 2, `np.inf` or \"inf\".')\n",
        "\n",
        "        if not (\n",
        "            isinstance(self.eps, (int, float))\n",
        "            and isinstance(self.eps_step, (int, float))\n",
        "            or isinstance(self.eps, np.ndarray)\n",
        "            and isinstance(self.eps_step, np.ndarray)\n",
        "        ):\n",
        "            raise TypeError(\n",
        "                \"The perturbation size `eps` and the perturbation step-size `eps_step` must have the same type of `int`\"\n",
        "                \", `float`, or `np.ndarray`.\"\n",
        "            )\n",
        "\n",
        "        if isinstance(self.eps, (int, float)):\n",
        "            if self.eps < 0:\n",
        "                raise ValueError(\"The perturbation size `eps` has to be nonnegative.\")\n",
        "        else:\n",
        "            if (self.eps < 0).any():\n",
        "                raise ValueError(\"The perturbation size `eps` has to be nonnegative.\")\n",
        "\n",
        "        if isinstance(self.eps_step, (int, float)):\n",
        "            if self.eps_step <= 0:\n",
        "                raise ValueError(\"The perturbation step-size `eps_step` has to be positive.\")\n",
        "        else:\n",
        "            if (self.eps_step <= 0).any():\n",
        "                raise ValueError(\"The perturbation step-size `eps_step` has to be positive.\")\n",
        "\n",
        "        if isinstance(self.eps, np.ndarray) and isinstance(self.eps_step, np.ndarray):\n",
        "            if self.eps.shape != self.eps_step.shape:\n",
        "                raise ValueError(\n",
        "                    \"The perturbation size `eps` and the perturbation step-size `eps_step` must have the same shape.\"\n",
        "                )\n",
        "\n",
        "        if not isinstance(self.targeted, bool):\n",
        "            raise ValueError(\"The flag `targeted` has to be of type bool.\")\n",
        "\n",
        "        if not isinstance(self.num_random_init, (int, np.int)):\n",
        "            raise TypeError(\"The number of random initialisations has to be of type integer\")\n",
        "\n",
        "        if self.num_random_init < 0:\n",
        "            raise ValueError(\"The number of random initialisations `random_init` has to be greater than or equal to 0.\")\n",
        "\n",
        "        if self.batch_size <= 0:\n",
        "            raise ValueError(\"The batch size `batch_size` has to be positive.\")\n",
        "\n",
        "        if not isinstance(self.minimal, bool):\n",
        "            raise ValueError(\"The flag `minimal` has to be of type bool.\")\n",
        "\n",
        "    def _compute_perturbation(\n",
        "        self, batch: np.ndarray, batch_labels: np.ndarray, mask: Optional[np.ndarray]\n",
        "    ) -> np.ndarray:\n",
        "        # Pick a small scalar to avoid division by 0\n",
        "        tol = 10e-8\n",
        "\n",
        "        # Get gradient wrt loss; invert it if attack is targeted\n",
        "        grad = self.estimator.loss_gradient(batch, batch_labels) * (1 - 2 * int(self.targeted))\n",
        "\n",
        "        # Write summary\n",
        "        if self.summary_writer is not None:\n",
        "            self.summary_writer.add_scalar(\n",
        "                \"gradients/norm-L1/batch-{}\".format(self._batch_id),\n",
        "                np.linalg.norm(grad.flatten(), ord=1),\n",
        "                global_step=self._i_max_iter,\n",
        "            )\n",
        "            self.summary_writer.add_scalar(\n",
        "                \"gradients/norm-L2/batch-{}\".format(self._batch_id),\n",
        "                np.linalg.norm(grad.flatten(), ord=2),\n",
        "                global_step=self._i_max_iter,\n",
        "            )\n",
        "            self.summary_writer.add_scalar(\n",
        "                \"gradients/norm-Linf/batch-{}\".format(self._batch_id),\n",
        "                np.linalg.norm(grad.flatten(), ord=np.inf),\n",
        "                global_step=self._i_max_iter,\n",
        "            )\n",
        "\n",
        "            if hasattr(self.estimator, \"compute_losses\"):\n",
        "                losses = self.estimator.compute_losses(x=batch, y=batch_labels)\n",
        "\n",
        "                for key, value in losses.items():\n",
        "                    self.summary_writer.add_scalar(\n",
        "                        \"loss/{}/batch-{}\".format(key, self._batch_id),\n",
        "                        np.mean(value.detach().cpu().numpy()),\n",
        "                        global_step=self._i_max_iter,\n",
        "                    )\n",
        "\n",
        "        # Check for NaN before normalisation an replace with 0\n",
        "        if grad.dtype != np.object and np.isnan(grad).any():\n",
        "            logger.warning(\"Elements of the loss gradient are NaN and have been replaced with 0.0.\")\n",
        "            grad = np.where(np.isnan(grad), 0.0, grad)\n",
        "        else:\n",
        "            for i, _ in enumerate(grad):\n",
        "                grad_i_array = grad[i].astype(np.float32)\n",
        "                if np.isnan(grad_i_array).any():\n",
        "                    grad[i] = np.where(np.isnan(grad_i_array), 0.0, grad_i_array).astype(np.object)\n",
        "\n",
        "        # Apply mask\n",
        "        if mask is not None:\n",
        "            grad = np.where(mask == 0.0, 0.0, grad)\n",
        "\n",
        "        # Apply norm bound\n",
        "        def _apply_norm(grad, object_type=False):\n",
        "            if (grad.dtype != np.object and np.isinf(grad).any()) or np.isnan(grad.astype(np.float32)).any():\n",
        "                logger.info(\"The loss gradient array contains at least one positive or negative infinity.\")\n",
        "\n",
        "            if self.norm in [np.inf, \"inf\"]:\n",
        "                grad = np.sign(grad)\n",
        "            elif self.norm == 1:\n",
        "                if not object_type:\n",
        "                    ind = tuple(range(1, len(batch.shape)))\n",
        "                else:\n",
        "                    ind = None\n",
        "                grad = grad / (np.sum(np.abs(grad), axis=ind, keepdims=True) + tol)\n",
        "            elif self.norm == 2:\n",
        "                if not object_type:\n",
        "                    ind = tuple(range(1, len(batch.shape)))\n",
        "                else:\n",
        "                    ind = None\n",
        "                grad = grad / (np.sqrt(np.sum(np.square(grad), axis=ind, keepdims=True)) + tol)\n",
        "            return grad\n",
        "\n",
        "        if batch.dtype == np.object:\n",
        "            for i_sample in range(batch.shape[0]):\n",
        "                grad[i_sample] = _apply_norm(grad[i_sample], object_type=True)\n",
        "                assert batch[i_sample].shape == grad[i_sample].shape\n",
        "        else:\n",
        "            grad = _apply_norm(grad)\n",
        "\n",
        "        assert batch.shape == grad.shape\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def _apply_perturbation(\n",
        "        self, batch: np.ndarray, perturbation: np.ndarray, eps_step: Union[int, float, np.ndarray]\n",
        "    ) -> np.ndarray:\n",
        "\n",
        "        perturbation_step = eps_step * perturbation\n",
        "        if perturbation_step.dtype != np.object:\n",
        "            perturbation_step[np.isnan(perturbation_step)] = 0\n",
        "        else:\n",
        "            for i, _ in enumerate(perturbation_step):\n",
        "                perturbation_step_i_array = perturbation_step[i].astype(np.float32)\n",
        "                if np.isnan(perturbation_step_i_array).any():\n",
        "                    perturbation_step[i] = np.where(\n",
        "                        np.isnan(perturbation_step_i_array), 0.0, perturbation_step_i_array\n",
        "                    ).astype(np.object)\n",
        "\n",
        "        batch = batch + perturbation_step\n",
        "        if self.estimator.clip_values is not None:\n",
        "            clip_min, clip_max = self.estimator.clip_values\n",
        "            batch = np.clip(batch, clip_min, clip_max)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def _compute(\n",
        "        self,\n",
        "        x: np.ndarray,\n",
        "        x_init: np.ndarray,\n",
        "        y: np.ndarray,\n",
        "        mask: Optional[np.ndarray],\n",
        "        eps: Union[int, float, np.ndarray],\n",
        "        eps_step: Union[int, float, np.ndarray],\n",
        "        project: bool,\n",
        "        random_init: bool,\n",
        "    ) -> np.ndarray:\n",
        "        if random_init:\n",
        "            n = x.shape[0]\n",
        "            m = np.prod(x.shape[1:]).item()\n",
        "            random_perturbation = random_sphere(n, m, eps, self.norm).reshape(x.shape).astype(ART_NUMPY_DTYPE)\n",
        "            if mask is not None:\n",
        "                random_perturbation = random_perturbation * (mask.astype(ART_NUMPY_DTYPE))\n",
        "            x_adv = x.astype(ART_NUMPY_DTYPE) + random_perturbation\n",
        "\n",
        "            if self.estimator.clip_values is not None:\n",
        "                clip_min, clip_max = self.estimator.clip_values\n",
        "                x_adv = np.clip(x_adv, clip_min, clip_max)\n",
        "        else:\n",
        "            if x.dtype == np.object:\n",
        "                x_adv = x.copy()\n",
        "            else:\n",
        "                x_adv = x.astype(ART_NUMPY_DTYPE)\n",
        "\n",
        "        # Compute perturbation with implicit batching\n",
        "        for batch_id in range(int(np.ceil(x.shape[0] / float(self.batch_size)))):\n",
        "            self._batch_id = batch_id\n",
        "            batch_index_1, batch_index_2 = batch_id * self.batch_size, (batch_id + 1) * self.batch_size\n",
        "            batch_index_2 = min(batch_index_2, x.shape[0])\n",
        "            batch = x_adv[batch_index_1:batch_index_2]\n",
        "            batch_labels = y[batch_index_1:batch_index_2]\n",
        "\n",
        "            mask_batch = mask\n",
        "            if mask is not None:\n",
        "                # Here we need to make a distinction: if the masks are different for each input, we need to index\n",
        "                # those for the current batch. Otherwise (i.e. mask is meant to be broadcasted), keep it as it is.\n",
        "                if len(mask.shape) == len(x.shape):\n",
        "                    mask_batch = mask[batch_index_1:batch_index_2]\n",
        "\n",
        "            # Get perturbation\n",
        "            perturbation = self._compute_perturbation(batch, batch_labels, mask_batch)\n",
        "\n",
        "            # Compute batch_eps and batch_eps_step\n",
        "            if isinstance(eps, np.ndarray) and isinstance(eps_step, np.ndarray):\n",
        "                if len(eps.shape) == len(x.shape) and eps.shape[0] == x.shape[0]:\n",
        "                    batch_eps = eps[batch_index_1:batch_index_2]\n",
        "                    batch_eps_step = eps_step[batch_index_1:batch_index_2]\n",
        "\n",
        "                else:\n",
        "                    batch_eps = eps\n",
        "                    batch_eps_step = eps_step\n",
        "\n",
        "            else:\n",
        "                batch_eps = eps\n",
        "                batch_eps_step = eps_step\n",
        "\n",
        "            # Apply perturbation and clip\n",
        "            x_adv[batch_index_1:batch_index_2] = self._apply_perturbation(batch, perturbation, batch_eps_step)\n",
        "\n",
        "            if project:\n",
        "                if x_adv.dtype == np.object:\n",
        "                    for i_sample in range(batch_index_1, batch_index_2):\n",
        "                        if isinstance(batch_eps, np.ndarray) and batch_eps.shape[0] == x_adv.shape[0]:\n",
        "                            perturbation = projection(\n",
        "                                x_adv[i_sample] - x_init[i_sample], batch_eps[i_sample], self.norm\n",
        "                            )\n",
        "\n",
        "                        else:\n",
        "                            perturbation = projection(x_adv[i_sample] - x_init[i_sample], batch_eps, self.norm)\n",
        "\n",
        "                        x_adv[i_sample] = x_init[i_sample] + perturbation\n",
        "\n",
        "                else:\n",
        "                    perturbation = projection(\n",
        "                        x_adv[batch_index_1:batch_index_2] - x_init[batch_index_1:batch_index_2], batch_eps, self.norm\n",
        "                    )\n",
        "                    x_adv[batch_index_1:batch_index_2] = x_init[batch_index_1:batch_index_2] + perturbation\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_mask(x: np.ndarray, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Get the mask from the kwargs.\n",
        "        :param x: An array with the original inputs.\n",
        "        :param mask: An array with a mask to be applied to the adversarial perturbations. Shape needs to be\n",
        "                     broadcastable to the shape of x. Any features for which the mask is zero will not be adversarially\n",
        "                     perturbed.\n",
        "        :type mask: `np.ndarray`\n",
        "        :return: The mask.\n",
        "        \"\"\"\n",
        "        mask = kwargs.get(\"mask\")\n",
        "\n",
        "        if mask is not None:\n",
        "            if mask.ndim > x.ndim:\n",
        "                raise ValueError(\"Mask shape must be broadcastable to input shape.\")\n",
        "\n",
        "            if not (np.issubdtype(mask.dtype, np.floating) or mask.dtype == np.bool):\n",
        "                raise ValueError(\n",
        "                    \"The `mask` has to be either of type np.float32, np.float64 or np.bool. The provided\"\n",
        "                    \"`mask` is of type {}.\".format(mask.dtype)\n",
        "                )\n",
        "\n",
        "            if np.issubdtype(mask.dtype, np.floating) and np.amin(mask) < 0.0:\n",
        "                raise ValueError(\n",
        "                    \"The `mask` of type np.float32 or np.float64 requires all elements to be either zero\"\n",
        "                    \"or positive values.\"\n",
        "                )\n",
        "\n",
        "        return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2z5CDqCOjhi"
      },
      "source": [
        "# **Esecuzione**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzZkC7HimlHT"
      },
      "source": [
        "##Creazione classificatore ART Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZL7c94zmlHU"
      },
      "source": [
        "from art.estimators.classification import PyTorchClassifier\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(0, 1),\n",
        "    loss=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.Adam(model.classifier.parameters(),lr=1e-5),\n",
        "    input_shape=(224, 224, 3),\n",
        "    nb_classes=class_number\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m10EkCq5GeEu"
      },
      "source": [
        "##Attacco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yk7RwELGfM4",
        "outputId": "f2540f57-cfdc-435f-c22b-c1e36df3e2f3"
      },
      "source": [
        "from art.utils import to_categorical\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "# FGM\n",
        "attack = FastGradientMethod_mod(estimator=classifier, eps=1000,minimal=True,eps_step=0.1)\n",
        "\n",
        "#x_test_adv=[] \n",
        "#y_test_adv=[] \n",
        "Test_p = pd.DataFrame()\n",
        "model.eval()\n",
        "model.cuda()\n",
        "prob=nn.Softmax()\n",
        "data_transform_test= transforms.Compose([transforms.Resize([224,224],interpolation=InterpolationMode.NEAREST),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])\n",
        "i=0\n",
        "for input,label in testgen:\n",
        "  i+=1\n",
        "\n",
        "  sys.stdout.write(\"\\rElem: {0}/{1}\".format(i,len(testgen)))\n",
        "  sys.stdout.flush()\n",
        "  \n",
        "  #input=data_transform_test(input) #prima faccio resize a 224 per calcolare le adv\n",
        "\n",
        "  y_test=np.array((to_categorical(label.numpy(),2)))\n",
        "  \n",
        "  x_test_adv=attack.generate(x=np.array(input.numpy()),y=y_test,target=True,class_target=classes_name.index('Live'),max_iter=100,confidence=0.7,transform=data_transform_test)[0,:,:,:]\n",
        "  \n",
        "  x_test_adv=torch.Tensor(x_test_adv)\n",
        "  x_test_adv=x_test_adv.unsqueeze_(0)\n",
        "  \n",
        "  x_test_adv=transf_init(x_test_adv) #faccio resize adv a 1000 per calcolare le patch\n",
        "\n",
        "  n=x_test_adv.shape\n",
        "  n_mod=calc_size(n[2:4])\n",
        "  crop_transform=transforms.TenCrop((n_mod[0],n_mod[1])).to(device)\n",
        "  crops=crop_transform(x_test_adv)\n",
        "  live=0\n",
        "  spoof=0\n",
        "  for crop in crops:\n",
        "    crop=data_transform_test(crop).to(device) #per ogni patch viene faccio il resize a 224 per il testing\n",
        "    outputs = model(crop)\n",
        "    live+=outputs[0][0]\n",
        "    spoof+=outputs[0][1]\n",
        "  live=live/10\n",
        "  spoof=spoof/10\n",
        "  probabilities=prob(torch.Tensor([live,spoof])).numpy()\n",
        "  Test_p = Test_p.append({'real': classes_name[int(label)] ,\n",
        "                          'predicted': classes_name[np.argmax([live,spoof])],\n",
        "                          'prob_live': round(probabilities[0],4),\n",
        "                          'prob_spoof': round(probabilities[1],4)},ignore_index = True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rElem: 1/2500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rElem: 2/2500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elem: 719/2500"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFKEoI-enb8L"
      },
      "source": [
        "##Testing\n",
        "\n",
        "> Trasforma i due testing in una funzione e richiamala due volte\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MmzfXhFt40W"
      },
      "source": [
        "###Print accuracy test orig from file & load pd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSOr1z85vhl7"
      },
      "source": [
        "Test_orig=pd.read_excel(pd_preds_value)\n",
        "true_label = Test_orig.real.values\n",
        "predicted = Test_orig.predicted.values\n",
        "accuracy=round((np.sum((true_label == predicted).astype(int)))/Test_orig.shape[0],4)*100\n",
        "print(\"\\nAccuracy: {0}\".format(accuracy))\n",
        "print(\"Shape dataframe: {0}\".format(Test_orig.shape))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmjrhHYsVsN"
      },
      "source": [
        "###Testing immagini spoof predette live prima e dopo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGuElPEOW3dZ"
      },
      "source": [
        "####Accuracy adv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp0jAIC-W5zC"
      },
      "source": [
        "true_label = Test_p.real.values\n",
        "predicted = Test_p.predicted.values\n",
        "accuracy=round((np.sum((true_label == predicted).astype(int)))/Test_p.shape[0],4)*100\n",
        "print(\"\\nAccuracy: {0}\".format(accuracy))\n",
        "print(\"Shape dataframe: {0}\".format(Test_p.shape)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyLoc2K6V_ar"
      },
      "source": [
        "####Spoof"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZwQC-osvGM"
      },
      "source": [
        "print(Test_orig)\n",
        "n_spoof=np.sum(Test_orig['real']=='Spoof')\n",
        "print(\"# img spoof: \"+str(n_spoof))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0SfSelFK2dl"
      },
      "source": [
        "prima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsNqIDAxsZBA"
      },
      "source": [
        "p=Test_orig.loc[Test_orig['real']=='Spoof']\n",
        "p1=p.loc[p['predicted']==p['real']]\n",
        "print(\"Img realmente spoof e predette spoof\")\n",
        "print(p1)\n",
        "n_spoof_pred=p1.count(0)[0]\n",
        "print(\"Numero di predizioni spoof giuste: \"+str(n_spoof_pred))\n",
        "print(\"Accuracy su img spoof: \"+str(round(n_spoof_pred/n_spoof*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AciVwgFyK3Xc"
      },
      "source": [
        "dopo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2xU5gUQuy7y"
      },
      "source": [
        "d=Test_p.loc[Test_p['real']=='Spoof']\n",
        "d1=d.loc[d['predicted']==d['real']]\n",
        "print(\"Img realmente spoof e predette spoof\")\n",
        "print(d1)\n",
        "n_spoof_pred2=d1.count(0)[0]\n",
        "print(\"Numero di predizioni spoof giuste: \"+str(n_spoof_pred2))\n",
        "print(\"Accuracy su img spoof: \"+str(round(n_spoof_pred2/n_spoof*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Q78IIqWCTI"
      },
      "source": [
        "####Live"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuxOWBYWTLk"
      },
      "source": [
        "print(Test_orig)\n",
        "n_live=np.sum(Test_orig['real']=='Live')\n",
        "print(\"# img live: \"+str(n_live))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtPKGqzEWCTI"
      },
      "source": [
        "prima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtB5Te35WCTJ"
      },
      "source": [
        "p=Test_orig.loc[Test_orig['real']=='Live']\n",
        "p1=p.loc[p['predicted']==p['real']]\n",
        "print(\"Img realmente live e predette live\")\n",
        "print(p1)\n",
        "n_live_pred=p1.count(0)[0]\n",
        "print(\"Numero di predizioni live giuste: \"+str(n_live_pred))\n",
        "print(\"Accuracy su img live: \"+str(round(n_live_pred/n_live*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3VNm1BCWCTJ"
      },
      "source": [
        "dopo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssG-LK1zWCTJ"
      },
      "source": [
        "d=Test_p.loc[Test_p['real']=='Live']\n",
        "d1=d.loc[d['predicted']==d['real']]\n",
        "print(\"Img realmente live e predette live\")\n",
        "print(d1)\n",
        "n_live_pred2=d1.count(0)[0]\n",
        "print(\"Numero di predizioni live giuste: \"+str(n_live_pred2))\n",
        "print(\"Accuracy su img live: \"+str(round(n_live_pred2/n_live*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBRYj9D8kFE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test_adv[0].numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}