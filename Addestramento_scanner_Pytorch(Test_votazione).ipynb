{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Addestramento_scanner_Pytorch(Test_votazione).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nGmEBN4oxqUO",
        "pIqUXUmoA541",
        "-ycpjmyb4Cxe",
        "dherpFOH0Uau",
        "O4hHndtkosDV",
        "ZazQQE8ypKP9",
        "3OpXAJ1SpiwI",
        "9XepXK-ny3XN",
        "PBSyijWDqY4-",
        "O_c2L3v0r2xG",
        "VRhT4XM1sVm-",
        "kJ6xDO5GGZY5",
        "tFFWkmjX2j5P"
      ],
      "mount_file_id": "1LFvCjg8zmdzf9GGORH3M3sLCejtQ0qUI",
      "authorship_tag": "ABX9TyMQsOM+cdR2e97riWU/zgjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f1ef23e652544a3994b01e350f2c12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac3ca7fd09854b7c8ffbda4206d22b80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3851454df39a43bab7ac1608836bf567",
              "IPY_MODEL_9f915593d72b411d9c1d1da3114d5c3e",
              "IPY_MODEL_5e5dff5c21a34de8a2e008dd1f75a30e"
            ]
          }
        },
        "ac3ca7fd09854b7c8ffbda4206d22b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3851454df39a43bab7ac1608836bf567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ffd50b7de78444ab59794868fb90522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a69a91ff6d224e7ba563d04a12b226f8"
          }
        },
        "9f915593d72b411d9c1d1da3114d5c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4a3fb11bbf044ba80b41680d9d8e2f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7014b823703e484d8eccee234bc01bc1"
          }
        },
        "5e5dff5c21a34de8a2e008dd1f75a30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_461e7454e08a4a86b88c46d194fadeae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:24&lt;00:00, 22.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb09bc64a4a540a7a46ad9374996dc32"
          }
        },
        "7ffd50b7de78444ab59794868fb90522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a69a91ff6d224e7ba563d04a12b226f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a3fb11bbf044ba80b41680d9d8e2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7014b823703e484d8eccee234bc01bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "461e7454e08a4a86b88c46d194fadeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb09bc64a4a540a7a46ad9374996dc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/Tesi/blob/main/Addestramento_scanner_Pytorch(Test_votazione).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoLiAGAtqBh"
      },
      "source": [
        "# **Init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "## Import librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RXI-DDIb3C"
      },
      "source": [
        "#Librerie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIqUXUmoA541"
      },
      "source": [
        "##Check device\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2pe5Zh2A4Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023ac823-64c7-4576-fac2-e882dc2f1df8"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "True\n",
            "Tesla K80\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "##Def variabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#scanner\n",
        "scanner_name = 'DigitalPersona'\n",
        "\n",
        "#salvataggio modello\n",
        "model_save_name = 'VGG19_prova2'\n",
        "path_model_save = F\"/content/gdrive/My Drive/ModelliCNN/Scanner/{scanner_name}/Pytorch/{model_save_name}\" \n",
        "\n",
        "#dataset\n",
        "pathDataset=F'/content/gdrive/MyDrive/Dataset_impronte/training/{scanner_name}_patch'\n",
        "pathTestset=F'/content/gdrive/MyDrive/Dataset_impronte/test/{scanner_name}'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsOZsUq1Yncj"
      },
      "source": [
        "##Parametri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ERW4gdtYos8"
      },
      "source": [
        "batch_size = 5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "##Collegamento google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvTOQw-aHRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a63c13-b5e7-4bb7-d4a8-eee5002567fb"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4b2eLxnouZ8"
      },
      "source": [
        "##Caricamento dataset e creazione Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS-Uzs8BjD4R"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "data_transform=transforms.Compose([transforms.Resize([224,224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(pathDataset,transform=data_transform)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2f0qqtT8Gsd",
        "outputId": "819771b3-187c-4d1e-99d8-8b3ea675483a"
      },
      "source": [
        "print(len(train_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazQQE8ypKP9"
      },
      "source": [
        "##Nomi classi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYk4cr4eo9Ir",
        "outputId": "aa7459bc-7cf5-4636-cf79-786db1356453"
      },
      "source": [
        "classes_name=train_dataset.classes\n",
        "class_number=len(classes_name)\n",
        "print(classes_name)\n",
        "print(class_number)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Live', 'Spoof']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XepXK-ny3XN"
      },
      "source": [
        "# **Creazione modello**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSyijWDqY4-"
      },
      "source": [
        "##Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymaBXhaPMvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "1f1ef23e652544a3994b01e350f2c12d",
            "ac3ca7fd09854b7c8ffbda4206d22b80",
            "3851454df39a43bab7ac1608836bf567",
            "9f915593d72b411d9c1d1da3114d5c3e",
            "5e5dff5c21a34de8a2e008dd1f75a30e",
            "7ffd50b7de78444ab59794868fb90522",
            "a69a91ff6d224e7ba563d04a12b226f8",
            "a4a3fb11bbf044ba80b41680d9d8e2f8",
            "7014b823703e484d8eccee234bc01bc1",
            "461e7454e08a4a86b88c46d194fadeae",
            "cb09bc64a4a540a7a46ad9374996dc32"
          ]
        },
        "outputId": "49101315-78c5-4086-f5f3-7cb48f301677"
      },
      "source": [
        "model_conv = models.vgg19(pretrained=True,progress=True)\n",
        "for param in model_conv.parameters():\n",
        "  param.requires_grad = False #non modifico i parametri della parte riguardante le features durante il training, poiché voglio usare quella parte così com'è stata pre-addestrata\n",
        "\n",
        "print(model_conv)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f1ef23e652544a3994b01e350f2c12d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_c2L3v0r2xG"
      },
      "source": [
        "##Aggiunta classificatore e freeze parametri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1qeI3_3qKJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0407c1-66bd-4c83-9f33-6e24dd4fc478"
      },
      "source": [
        "model_conv.classifier[6]=nn.Linear(4096,class_number)\n",
        "\n",
        "for param in model_conv.classifier.parameters():\n",
        "  param.requires_grad = True #invece pongo il calcolo del gradiente del classificatore, ovvero attivo il calcolo dei pesi\n",
        "\n",
        "print(model_conv) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVE_mjLtMpz"
      },
      "source": [
        "#**Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSAc21gAk70m"
      },
      "source": [
        "##Def train definitiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xk71F1Yk9yZ"
      },
      "source": [
        "from collections import OrderedDict\n",
        "from functools import partial\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "from functools import partial\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "##### Data utils #####\n",
        "\n",
        "def log_to_message(log):\n",
        "    fmt = \"{0}: {1}\"\n",
        "    return \"    \".join(fmt.format(k, v) for k, v in log.items())\n",
        "\n",
        "\n",
        "class ProgressBar(object):\n",
        "    \"\"\"Cheers @ajratner\"\"\"\n",
        "\n",
        "    def __init__(self, n, length=40):\n",
        "        # Protect against division by zero\n",
        "        self.n      = max(1, n)\n",
        "        self.nf     = float(n)\n",
        "        self.length = length\n",
        "        # Precalculate the i values that should trigger a write operation\n",
        "        #self.ticks = set([round(i/100.0 * n) for i in range(101)])\n",
        "        #self.ticks.add(n-1)\n",
        "        self.ticks=range(n)\n",
        "        self.bar(0)\n",
        "\n",
        "    def bar(self, i, message=\"\"):\n",
        "        \"\"\"Assumes i ranges through [0, n-1]\"\"\"\n",
        "        if i in self.ticks:\n",
        "            b = int(np.ceil(((i+1) / self.nf) * self.length))\n",
        "            sys.stdout.write(\"\\r[{0}{1}] {2}%\\t{3}\".format(\n",
        "                \"=\"*b, \" \"*(self.length-b), int(100*((i+1) / self.nf)), message\n",
        "            ))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    def close(self, message=\"\"):\n",
        "        # Move the bar to 100% before closing\n",
        "        self.bar(self.n-1)\n",
        "        sys.stdout.write(\"{0}\\n\\n\".format(message))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "def training_f(train_dataset, numEpochs, model_conv, criterionCNN, optimizer_conv,batch_size, validation_split=0):\n",
        "  \n",
        "  best_acc = 0\n",
        "  best_loss=0\n",
        "  best_epoca = 0\n",
        "  \n",
        "  best_model_wts = copy.deepcopy(model_conv.state_dict())\n",
        "\n",
        "  if validation_split:\n",
        "      train_size = int(len(train_dataset) * 0.8)\n",
        "      val_size = len(train_dataset) - train_size\n",
        "      train_dataset, val_set = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "      traingen = torch.utils.data.DataLoader(train_dataset, pin_memory=True, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "      valgen = torch.utils.data.DataLoader(val_set, pin_memory=True, batch_size=batch_size)\n",
        "  \n",
        "  else: traingen = torch.utils.data.DataLoader(train_dataset, pin_memory=True, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "      \n",
        "  for epochs in range(1,numEpochs + 1):\n",
        "    since = time.time()\n",
        "    \n",
        "    print(\"Epoch {0} / {1}\".format(epochs, numEpochs))\n",
        "    log = OrderedDict()\n",
        "    modelLoss_train = 0.0\n",
        "    modelAcc_train = 0.0\n",
        "    \n",
        "    model_conv.train() \n",
        "    \n",
        "    totalSize = 0\n",
        "    batch_i=0\n",
        "    num_batch=int(np.ceil(len(train_dataset)/batch_size))\n",
        "    pb = ProgressBar(num_batch)\n",
        "    #for each batch: operazioni per gli algoritmi di ottimizzazione\n",
        "    for inputs,labels in traingen:\n",
        "      inputs = inputs.type(torch.FloatTensor).cuda()\n",
        "      labels = labels.cuda()\n",
        "      \n",
        "      batch_i=batch_i+1\n",
        "      \n",
        "      optimizer_conv.zero_grad()\n",
        "      model_conv.zero_grad()\n",
        "      \n",
        "      y = model_conv(inputs)\n",
        "      outp, preds = torch.max(y, 1)   \n",
        "        \n",
        "      lossCNN = criterionCNN(y, labels) #media per batch\n",
        "\n",
        "      modelLoss_train += lossCNN.item() * inputs.size(0)\n",
        "      totalSize += inputs.size(0)\n",
        "      modelAcc_train += torch.sum(preds == labels.data).item()\n",
        "\n",
        "      log['batch']=\"{0} / {1}\".format(batch_i, num_batch)\n",
        "      log['loss'] =round(modelLoss_train/totalSize,2)\n",
        "      log['acc']=round(modelAcc_train/totalSize,2)\n",
        "      log['Validation']=False\n",
        "      pb.bar(batch_i, log_to_message(log))\n",
        "\n",
        "      lossCNN.backward()  # pred = f(x)   -> loss = L(f(x), l_true)\n",
        "      \n",
        "      optimizer_conv.step()\n",
        "    \n",
        "    #calcolo loss e accuracy\n",
        "    modelLoss_epoch_train = modelLoss_train/totalSize\n",
        "    modelAcc_epoch_train  = modelAcc_train/totalSize\n",
        "    \n",
        "    log['loss']=modelLoss_epoch_train\n",
        "    log['acc']=modelAcc_epoch_train\n",
        "    pb.close(log_to_message(log))\n",
        "\n",
        "    if validation_split:    \n",
        "        #validation\n",
        "               \n",
        "        model_conv.eval()\n",
        "        totalSize_val = 0\n",
        "        modelLoss_val = 0.0\n",
        "        modelAcc_val = 0.0\n",
        "\n",
        "        log['Validation']=True\n",
        "        log['loss_val']=modelLoss_val\n",
        "        log['acc_val']=modelAcc_val\n",
        "        pb.close(log_to_message(log))\n",
        "\n",
        "        for inputs,labels in valgen:\n",
        "          inputs = inputs.type(torch.FloatTensor).cuda()\n",
        "          labels = labels.cuda()\n",
        "          \n",
        "          y = model_conv(inputs)\n",
        "          outp, preds = torch.max(y, 1)\n",
        "          lossCNN = criterionCNN(y, labels)\n",
        "\n",
        "          modelLoss_val += lossCNN.item() * inputs.size(0)\n",
        "          totalSize_val += inputs.size(0)\n",
        "          modelAcc_val += torch.sum(preds == labels.data).item()        \n",
        "\n",
        "          log['loss_val'] =round(modelLoss_val/totalSize_val,2)\n",
        "          log['acc_val']=round(modelAcc_val/totalSize_val,2)\n",
        "          pb.close(log_to_message(log))\n",
        "\n",
        "        modelLoss_epoch_val=modelLoss_val/totalSize_val\n",
        "        modelAcc_epoch_val = modelAcc_val/totalSize_val\n",
        "        time_elapsed = time.time()-since\n",
        "\n",
        "        log['loss_val'] =round(modelLoss_epoch_val,2)\n",
        "        log['acc_val']=round(modelAcc_epoch_val,2)\n",
        "        log['time']=round(time_elapsed,2)\n",
        "        \n",
        "        if (modelAcc_epoch_val > best_acc) or (modelAcc_epoch_val == best_acc and modelLoss_epoch_val < best_loss) :\n",
        "          best_acc = modelAcc_epoch_val\n",
        "          best_loss = modelLoss_epoch_val\n",
        "          best_epoca = epochs\n",
        "          best_model_wts = copy.deepcopy(model_conv.state_dict())\n",
        "          \n",
        "    else: \n",
        "      best_model_wts = copy.deepcopy(model_conv.state_dict())\n",
        "      \n",
        "  #pb.close(log_to_message(log))\n",
        "\n",
        "  model_conv.load_state_dict(best_model_wts)\n",
        "  return model_conv\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRhT4XM1sVm-"
      },
      "source": [
        "##Set iperparametri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1X3BB5sX6w"
      },
      "source": [
        "#iper-parametri iniziali\n",
        "learning_rate = 1e-4\n",
        "momentum=0.9\n",
        "num_epoch = 10\n",
        "\n",
        "#richiamo funzione che effettua il training con validation\n",
        "\n",
        "model_conv = model_conv.cuda() #sposta i calcoli sulla gpu\n",
        "criterion = nn.CrossEntropyLoss() #criterio dell'aggiornamento del gradiente: minimizzazione funzione loss entropia\n",
        "optimizer_conv = optim.SGD(model_conv.classifier.parameters(),lr=learning_rate,momentum=momentum)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44j4JhI0ti8T"
      },
      "source": [
        "##Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "1Cu1TY-Ttlgc",
        "outputId": "867441f5-8c99-41c1-c496-e32c9efc6562"
      },
      "source": [
        "best_model=training_f(train_dataset, num_epoch, model_conv, criterion, optimizer_conv,batch_size=5, validation_split=0.2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10\n",
            "\r[=                                       ] 0%\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[========================================] 100%\tbatch: 3200 / 3200    loss: 0.21453289753061655    acc: 0.909125    Validation: False\n",
            "\n",
            "[========================================] 100%\tbatch: 3200 / 3200    loss: 0.21453289753061655    acc: 0.909125    Validation: True    loss_val: 0.0    acc_val: 0.0\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5b0e89720317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d33437130f9d>\u001b[0m in \u001b[0;36mtraining_f\u001b[0;34m(train_dataset, numEpochs, model_conv, criterionCNN, optimizer_conv, batch_size, validation_split)\u001b[0m\n\u001b[1;32m    142\u001b[0m           \u001b[0mmodelAcc_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m           \u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_val'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLoss_epoch_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotalSize_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m           \u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelAcc_epoch_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotalSize_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m           \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_to_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'modelLoss_epoch_val' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAU1QYvhrGVs"
      },
      "source": [
        "#**Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmnQizLIrQVJ"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtPmfqdrIg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf155c2-761a-43bd-b41a-0652067e5e20"
      },
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "best_model=model_conv\n",
        "Test = pd.DataFrame()\n",
        "best_model.eval()\n",
        "best_model.cuda()\n",
        "\n",
        "data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "        #transforms.ToTensor(),\n",
        "        transforms.TenCrop([180,180]),\n",
        "        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "Directory = os.listdir(pathTestset)\n",
        "for classe in Directory:\n",
        "  classes_path = os.listdir(pathTestset +\"/\"+ classe)  \n",
        "  print(classe)\n",
        "  for input in classes_path:\n",
        "    if input.endswith('.png'):  \n",
        "      img = Image.open(pathTestset+\"/\"+classe+'/' + input)\n",
        "      crops = data_transform_test(img).to(device)\n",
        "      preds=[]\n",
        "      for crop in crops:\n",
        "        crop=crop.unsqueeze_(0)\n",
        "        outputs = best_model(crop)\n",
        "        _, predicted = torch.max(outputs, 1)  \n",
        "        preds.append(predicted.item())\n",
        "      if preds.count(0)>5: predicted=0\n",
        "      else: predicted=1\n",
        "\n",
        "      Test = Test.append({'img': input.split('.')[0],\n",
        "                          'predicted': classes_name[predicted],\n",
        "                          'real': classe} ,ignore_index = True) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Live\n",
            "Spoof\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tCHClGZsZAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ddfb2c-06c5-402c-c594-1b2cd72db525"
      },
      "source": [
        "true_label = Test.real.values\n",
        "predicted = Test.predicted.values\n",
        "\n",
        "print(round((np.sum((true_label == predicted).astype(int)))/Test.shape[0],4)*100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFFWkmjX2j5P"
      },
      "source": [
        "#**Salvataggio modello**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAie77UO2nTs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "5ab4dd36-46fa-4010-c4ff-4f644f060fa5"
      },
      "source": [
        "#salva modello su drive\n",
        "torch.save(best_model.state_dict(),path_model_save)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b689bee5341d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    torch.save(best_model.)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}