{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attacco_PGD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lcoLiAGAtqBh",
        "OHENSlCXxzcr",
        "nGmEBN4oxqUO",
        "pIqUXUmoA541",
        "-ycpjmyb4Cxe",
        "dherpFOH0Uau",
        "5X10jetEyAax",
        "fETy1V2abbWo",
        "_miDmRukbbWq",
        "AJ_O-UAECNMk",
        "9XepXK-ny3XN",
        "PBSyijWDqY4-",
        "O_c2L3v0r2xG",
        "0OdO07YuUOFS",
        "kJ6xDO5GGZY5",
        "OVSi44LIk0TX",
        "OzZkC7HimlHT",
        "ZFKEoI-enb8L"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9be072fb8bb34069a284fd4f6bba9abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92b7894f677e4f078322acbe06fdb3b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e17dc67662a64ae89cad68b1f69874cb",
              "IPY_MODEL_ead12717f98b4c0c83c0a56f06827929",
              "IPY_MODEL_3e3fe07be4f4435f8238b8e1adef2414"
            ]
          }
        },
        "92b7894f677e4f078322acbe06fdb3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e17dc67662a64ae89cad68b1f69874cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94421d130b36484ea7c4531b81cfb5df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_459d9bb5912b4ce5bba6dc57fbb0d6e8"
          }
        },
        "ead12717f98b4c0c83c0a56f06827929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff2513214f1340338a316e02eb2947f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_729078a14d464268baa35c59107b0ee2"
          }
        },
        "3e3fe07be4f4435f8238b8e1adef2414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9130d1f3ca7e40a8bc76ee40d6f413f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:20&lt;00:00, 20.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07c8ef648b0444a397c2e34312edeb6b"
          }
        },
        "94421d130b36484ea7c4531b81cfb5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "459d9bb5912b4ce5bba6dc57fbb0d6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff2513214f1340338a316e02eb2947f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "729078a14d464268baa35c59107b0ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9130d1f3ca7e40a8bc76ee40d6f413f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07c8ef648b0444a397c2e34312edeb6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/Tesi/blob/main/Impronte/AttaccoScanner/Attacco_PGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoLiAGAtqBh"
      },
      "source": [
        "# **Init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHENSlCXxzcr"
      },
      "source": [
        "##Import ART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKN5Oqa-i6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89de2dc-0a50-4189-bfec-0284ba69a820"
      },
      "source": [
        "#importa ART\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.8.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Collecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.0.1)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.8.1 llvmlite-0.37.0 numba-0.54.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "## Import librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RXI-DDIb3C"
      },
      "source": [
        "#Librerie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "#import time\n",
        "#import os\n",
        "#import shutil\n",
        "#import copy\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIqUXUmoA541"
      },
      "source": [
        "##Check device\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2pe5Zh2A4Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f41cb4f-74a2-4034-b743-39da5fd99907"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n",
            "True\n",
            "Tesla P100-PCIE-16GB\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WApYIVcnU9sq"
      },
      "source": [
        "##Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi_cyTbXU-8s"
      },
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "transf_init=transforms.Resize(size=(1000,1000),interpolation=InterpolationMode.NEAREST)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "##Def path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#scanner\n",
        "scanner_name = 'HiScan'\n",
        "\n",
        "#salvataggio modello\n",
        "model_name = 'VGG19_10epoc_lr5_bs200_adam'\n",
        "path_model = F\"/content/gdrive/My Drive/ModelliCNN/Scanner/{scanner_name}/{model_name}\" \n",
        "\n",
        "#dataset\n",
        "pathTestset=F'/content/gdrive/MyDrive/Dataset_impronte/test/{scanner_name}'\n",
        "\n",
        "pd_preds_value=F'/content/gdrive/MyDrive/Dataset_impronte/test/Preds_value/{scanner_name}.xlsx'\n",
        "\n",
        "data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "##Collegamento google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvTOQw-aHRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cce2976-6b97-4e38-f000-034606ec8d44"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fETy1V2abbWo"
      },
      "source": [
        "##Caricamento dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMW6yAMPbbWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc09e156-ee08-412f-e63d-48de580fdea3"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(pathTestset,transforms.ToTensor())\n",
        "dim_set=len(test_dataset)\n",
        "print(dim_set)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_miDmRukbbWq"
      },
      "source": [
        "##Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3JB4rWJbbWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc69dfed-447c-486a-e5e0-e6b43a6c4b76"
      },
      "source": [
        "testgen=torch.utils.data.DataLoader(test_dataset, pin_memory=True, batch_size=1,num_workers=2)\n",
        "print(len(testgen))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazQQE8ypKP9"
      },
      "source": [
        "##Nomi classi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYk4cr4eo9Ir",
        "outputId": "d1a33513-ef18-4cd9-e04e-066ae89c6fdb"
      },
      "source": [
        "classes_name=test_dataset.classes\n",
        "class_number=len(classes_name)\n",
        "print(classes_name)\n",
        "print(class_number)\n",
        "#del test_dataset"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Live', 'Spoof']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ_O-UAECNMk"
      },
      "source": [
        "#**Riduzione dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnOEmgNRbbWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1709500d-805c-478c-cf8e-fb374a9d1529"
      },
      "source": [
        "test_dataset.samples=test_dataset.samples[997:1002]\n",
        "test_dataset.targets=test_dataset.targets[997:1002]\n",
        "\n",
        "dim_set=len(test_dataset)\n",
        "print(dim_set)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XepXK-ny3XN"
      },
      "source": [
        "# **Creazione modello**\n",
        "\n",
        "> non ho bloccato i parametri inferiori e sbloccato quelli del classificatore, vedi se funziona\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSyijWDqY4-"
      },
      "source": [
        "##Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymaBXhaPMvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "9be072fb8bb34069a284fd4f6bba9abe",
            "92b7894f677e4f078322acbe06fdb3b5",
            "e17dc67662a64ae89cad68b1f69874cb",
            "ead12717f98b4c0c83c0a56f06827929",
            "3e3fe07be4f4435f8238b8e1adef2414",
            "94421d130b36484ea7c4531b81cfb5df",
            "459d9bb5912b4ce5bba6dc57fbb0d6e8",
            "ff2513214f1340338a316e02eb2947f6",
            "729078a14d464268baa35c59107b0ee2",
            "9130d1f3ca7e40a8bc76ee40d6f413f6",
            "07c8ef648b0444a397c2e34312edeb6b"
          ]
        },
        "outputId": "53476b1a-1a0b-4ade-dfcf-4837585c1c96"
      },
      "source": [
        "model = models.vgg19(pretrained=True,progress=True)\n",
        "#model = models.densenet201(pretrained=True,progress=True)\n",
        "#print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9be072fb8bb34069a284fd4f6bba9abe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_c2L3v0r2xG"
      },
      "source": [
        "##Aggiunta classificatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1qeI3_3qKJJ"
      },
      "source": [
        "model.classifier[6]=nn.Linear(4096,2) #per vgg19\n",
        "#model.classifier=nn.Linear(1920,2) #per densenet201\n",
        "\n",
        "#print(model) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOHqOuTVAMaz"
      },
      "source": [
        "##Load pesi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEXv4tQ3AOi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25e3003-61bd-4a11-b688-df47c0eed8c6"
      },
      "source": [
        "model.load_state_dict(torch.load(path_model))#,map_location=torch.device('cpu')))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kr1yAn2UBl"
      },
      "source": [
        "# **Def funzioni**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdO07YuUOFS"
      },
      "source": [
        "##calc size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EAve-4iUPk1"
      },
      "source": [
        "def calc_size(n):\n",
        "  '''\n",
        "  n: int \n",
        "  return: 80% of n\n",
        "  '''\n",
        "  return tuple(int(np.ceil(i * (80/100))) for i in n)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6xDO5GGZY5"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xth1SmbAne7T"
      },
      "source": [
        "con media senza datframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VvGULk0ng1S"
      },
      "source": [
        "def test_average_preds(classifier,test_loader,):\n",
        "  '''\n",
        "  model: model trained\n",
        "  test_loader: dataloader \n",
        "  return: dataframe{n_img,class_predicted,class_real}\n",
        "  '''\n",
        "  preds=[]\n",
        "  #value=[]\n",
        "  prob=nn.Softmax()\n",
        "  data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])\n",
        "  i=0\n",
        "  for input,label in test_loader:\n",
        "    i+=1\n",
        "    input=transf_init(input) #resize 1000\n",
        "    n=input.shape\n",
        "    n_mod=calc_size(n[2:4])\n",
        "    crop_transform=transforms.TenCrop((n_mod[0],n_mod[1]))\n",
        "    crops=crop_transform(input)\n",
        "    live=0\n",
        "    spoof=0\n",
        "    for crop in crops:\n",
        "      crop=data_transform_test(crop) #resize 224\n",
        "      outputs = classifier.predict(crop)\n",
        "      live+=outputs[0][0]\n",
        "      spoof+=outputs[0][1]\n",
        "    live=live/10\n",
        "    spoof=spoof/10\n",
        "    predicted=np.argmax([live,spoof])\n",
        "    preds.append(predicted)\n",
        "    #value.append(np.max(prob(torch.Tensor([live,spoof])).numpy()))\n",
        "    value=np.max(prob(torch.Tensor([live,spoof])).numpy())\n",
        "\n",
        "  return np.array(preds),value"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVSi44LIk0TX"
      },
      "source": [
        "##Array to dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YarvS4XUk2Ka"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def array2dataloader(x,y):\n",
        "  '''\n",
        "  :param x: ndarray x_test;\n",
        "  :param y: labels with two value\n",
        "  '''\n",
        "  tensor_x = torch.Tensor(x) # transform to torch tensor\n",
        "  tensor_y = torch.Tensor(np.argmax(y,axis=1))\n",
        "\n",
        "  my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "  return DataLoader(my_dataset) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtOAEGt4Mmoh"
      },
      "source": [
        "##APGD mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5xioHKgMoWn"
      },
      "source": [
        "import logging\n",
        "import math\n",
        "from typing import Optional, Union, TYPE_CHECKING\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import trange\n",
        "\n",
        "from art.config import ART_NUMPY_DTYPE\n",
        "from art.attacks.attack import EvasionAttack\n",
        "from art.estimators.estimator import BaseEstimator, LossGradientsMixin\n",
        "from art.estimators.classification.classifier import ClassifierMixin\n",
        "from art.utils import check_and_transform_label_format, projection, random_sphere, is_probability, get_labels_np_array\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from art.utils import CLASSIFIER_LOSS_GRADIENTS_TYPE\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class AutoProjectedGradientDescent_mod(EvasionAttack):\n",
        "    \"\"\"\n",
        "    Implementation of the `Auto Projected Gradient Descent` attack.\n",
        "    | Paper link: https://arxiv.org/abs/2003.01690\n",
        "    \"\"\"\n",
        "\n",
        "    attack_params = EvasionAttack.attack_params + [\n",
        "        \"norm\",\n",
        "        \"eps\",\n",
        "        \"eps_step\",\n",
        "        \"max_iter\",\n",
        "        \"targeted\",\n",
        "        \"nb_random_init\",\n",
        "        \"batch_size\",\n",
        "        \"loss_type\",\n",
        "        \"verbose\",\n",
        "    ]\n",
        "    _estimator_requirements = (BaseEstimator, LossGradientsMixin, ClassifierMixin)\n",
        "    _predefined_losses = [None, \"cross_entropy\", \"difference_logits_ratio\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        estimator: \"CLASSIFIER_LOSS_GRADIENTS_TYPE\",\n",
        "        norm: Union[int, float, str] = np.inf,\n",
        "        eps: float = 0.3,\n",
        "        eps_step: float = 0.1,\n",
        "        max_iter: int = 100,\n",
        "        targeted: bool = False,\n",
        "        nb_random_init: int = 5,\n",
        "        batch_size: int = 32,\n",
        "        loss_type: Optional[str] = None,\n",
        "        verbose: bool = True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Create a :class:`.AutoProjectedGradientDescent` instance.\n",
        "        :param estimator: An trained estimator.\n",
        "        :param norm: The norm of the adversarial perturbation. Possible values: \"inf\", np.inf, 1 or 2.\n",
        "        :param eps: Maximum perturbation that the attacker can introduce.\n",
        "        :param eps_step: Attack step size (input variation) at each iteration.\n",
        "        :param max_iter: The maximum number of iterations.\n",
        "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False).\n",
        "        :param nb_random_init: Number of random initialisations within the epsilon ball. For num_random_init=0\n",
        "            starting at the original input.\n",
        "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
        "        :param loss_type: Defines the loss to attack. Available options: None (Use loss defined by estimator),\n",
        "            \"cross_entropy\", or \"difference_logits_ratio\"\n",
        "        :param verbose: Show progress bars.\n",
        "        \"\"\"\n",
        "        from art.estimators.classification import TensorFlowClassifier, TensorFlowV2Classifier, PyTorchClassifier\n",
        "\n",
        "        if loss_type not in self._predefined_losses:\n",
        "            raise ValueError(\n",
        "                \"The argument loss_type has an invalid value. The following options for `loss_type` are currently \"\n",
        "                \"supported: {}\".format(self._predefined_losses)\n",
        "            )\n",
        "\n",
        "        if loss_type is None:\n",
        "            if hasattr(estimator, \"predict\") and is_probability(\n",
        "                estimator.predict(x=np.ones(shape=(1, *estimator.input_shape), dtype=np.float32))\n",
        "            ):\n",
        "                raise ValueError(\n",
        "                    \"AutoProjectedGradientDescent is expecting logits as estimator output, the provided \"\n",
        "                    \"estimator seems to predict probabilities.\"\n",
        "                )\n",
        "\n",
        "            estimator_apgd = estimator\n",
        "        else:\n",
        "            if isinstance(estimator, TensorFlowClassifier):\n",
        "                import tensorflow as tf\n",
        "\n",
        "                if loss_type == \"cross_entropy\":\n",
        "                    if is_probability(estimator.predict(x=np.ones(shape=(1, *estimator.input_shape)))):\n",
        "                        raise NotImplementedError(\"Cross-entropy loss is not implemented for probability output.\")\n",
        "\n",
        "                    self._loss_object = tf.reduce_mean(\n",
        "                        tf.keras.losses.categorical_crossentropy(\n",
        "                            y_pred=estimator._output, y_true=estimator._labels_ph, from_logits=True\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                elif loss_type == \"difference_logits_ratio\":\n",
        "                    if is_probability(estimator.predict(x=np.ones(shape=(1, *estimator.input_shape)))):\n",
        "                        raise ValueError(\n",
        "                            \"The provided estimator seems to predict probabilities. \"\n",
        "                            \"If loss_type='difference_logits_ratio' the estimator has to to predict logits.\"\n",
        "                        )\n",
        "\n",
        "                    raise ValueError(\n",
        "                        \"The loss `difference_logits_ratio` has not been validate completely. It seems that the \"\n",
        "                        \"commented implemented below is failing to selected the second largest logit for cases \"\n",
        "                        \"where the largest logit is the true logit. For future work `difference_logits_ratio` and \"\n",
        "                        \"loss_fn should return the same loss value.\"\n",
        "                    )\n",
        "\n",
        "                    # def difference_logits_ratio(y_true, y_pred):\n",
        "                    #     i_y_true = tf.cast(tf.math.argmax(tf.cast(y_true, tf.int32), axis=1), tf.int32)\n",
        "                    #     i_y_pred_arg = tf.argsort(y_pred, axis=1)\n",
        "                    #     # Not completely sure if the following line is correct.\n",
        "                    #     # `i_y_pred_arg[:, -2], i_y_pred_arg[:, -1]` seems closer to the output of `loss_fn` than\n",
        "                    #     # `i_y_pred_arg[:, -1], i_y_pred_arg[:, -2]`\n",
        "                    #     i_z_i = tf.where(i_y_pred_arg[:, -1] != i_y_true[:], i_y_pred_arg[:, -2],\n",
        "                    #                      i_y_pred_arg[:, -1])\n",
        "                    #\n",
        "                    #     z_1 = tf.gather(y_pred, i_y_pred_arg[:, -1], axis=1, batch_dims=0)\n",
        "                    #     z_3 = tf.gather(y_pred, i_y_pred_arg[:, -3], axis=1, batch_dims=0)\n",
        "                    #     z_i = tf.gather(y_pred, i_z_i, axis=1, batch_dims=0)\n",
        "                    #     z_y = tf.gather(y_pred, i_y_true, axis=1, batch_dims=0)\n",
        "                    #\n",
        "                    #     z_1 = tf.linalg.diag_part(z_1)\n",
        "                    #     z_3 = tf.linalg.diag_part(z_3)\n",
        "                    #     z_i = tf.linalg.diag_part(z_i)\n",
        "                    #     z_y = tf.linalg.diag_part(z_y)\n",
        "                    #\n",
        "                    #     dlr = -(z_y - z_i) / (z_1 - z_3)\n",
        "                    #\n",
        "                    #     return tf.reduce_mean(dlr)\n",
        "                    #\n",
        "                    # def loss_fn(y_true, y_pred):\n",
        "                    #     i_y_true = np.argmax(y_true, axis=1)\n",
        "                    #     i_y_pred_arg = np.argsort(y_pred, axis=1)\n",
        "                    #     i_z_i = np.where(i_y_pred_arg[:, -1] != i_y_true[:], i_y_pred_arg[:, -1],\n",
        "                    #                      i_y_pred_arg[:, -2])\n",
        "                    #\n",
        "                    #     z_1 = y_pred[:, i_y_pred_arg[:, -1]]\n",
        "                    #     z_3 = y_pred[:, i_y_pred_arg[:, -3]]\n",
        "                    #     z_i = y_pred[:, i_z_i]\n",
        "                    #     z_y = y_pred[:, i_y_true]\n",
        "                    #\n",
        "                    #     z_1 = np.diag(z_1)\n",
        "                    #     z_3 = np.diag(z_3)\n",
        "                    #     z_i = np.diag(z_i)\n",
        "                    #     z_y = np.diag(z_y)\n",
        "                    #\n",
        "                    #     dlr = -(z_y - z_i) / (z_1 - z_3)\n",
        "                    #\n",
        "                    #     return np.mean(dlr)\n",
        "                    #\n",
        "                    # self._loss_fn = loss_fn\n",
        "                    # self._loss_object = difference_logits_ratio(y_true=estimator._labels_ph,\n",
        "                    #                                             y_pred=estimator._output)\n",
        "\n",
        "                estimator_apgd = TensorFlowClassifier(\n",
        "                    input_ph=estimator._input_ph,\n",
        "                    output=estimator._output,\n",
        "                    labels_ph=estimator._labels_ph,\n",
        "                    train=estimator._train,\n",
        "                    loss=self._loss_object,\n",
        "                    learning=estimator._learning,\n",
        "                    sess=estimator._sess,\n",
        "                    channels_first=estimator.channels_first,\n",
        "                    clip_values=estimator.clip_values,\n",
        "                    preprocessing_defences=estimator.preprocessing_defences,\n",
        "                    postprocessing_defences=estimator.postprocessing_defences,\n",
        "                    preprocessing=estimator.preprocessing,\n",
        "                    feed_dict=estimator._feed_dict,\n",
        "                )\n",
        "\n",
        "            elif isinstance(estimator, TensorFlowV2Classifier):\n",
        "                import tensorflow as tf\n",
        "\n",
        "                if loss_type == \"cross_entropy\":\n",
        "                    if is_probability(estimator.predict(x=np.ones(shape=(1, *estimator.input_shape)))):\n",
        "                        self._loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "                    else:\n",
        "                        self._loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "                elif loss_type == \"difference_logits_ratio\":\n",
        "                    if is_probability(estimator.predict(x=np.ones(shape=(1, *estimator.input_shape)))):\n",
        "                        raise ValueError(\n",
        "                            \"The provided estimator seems to predict probabilities. \"\n",
        "                            \"If loss_type='difference_logits_ratio' the estimator has to to predict logits.\"\n",
        "                        )\n",
        "\n",
        "                    class DifferenceLogitsRatioTensorFlowV2:\n",
        "                        \"\"\"\n",
        "                        Callable class for Difference Logits Ratio loss in TensorFlow v2.\n",
        "                        \"\"\"\n",
        "\n",
        "                        def __init__(self):\n",
        "                            self.reduction = \"mean\"\n",
        "\n",
        "                        def __call__(self, y_true, y_pred):\n",
        "                            i_y_true = tf.cast(tf.math.argmax(tf.cast(y_true, tf.int32), axis=1), tf.int32)\n",
        "                            i_y_pred_arg = tf.argsort(y_pred, axis=1)\n",
        "                            i_z_i_list = list()\n",
        "\n",
        "                            for i in range(y_true.shape[0]):\n",
        "                                if i_y_pred_arg[i, -1] != i_y_true[i]:\n",
        "                                    i_z_i_list.append(i_y_pred_arg[i, -1])\n",
        "                                else:\n",
        "                                    i_z_i_list.append(i_y_pred_arg[i, -2])\n",
        "\n",
        "                            i_z_i = tf.stack(i_z_i_list)\n",
        "\n",
        "                            z_1 = tf.gather(y_pred, i_y_pred_arg[:, -1], axis=1, batch_dims=0)\n",
        "                            z_3 = tf.gather(y_pred, i_y_pred_arg[:, -3], axis=1, batch_dims=0)\n",
        "                            z_i = tf.gather(y_pred, i_z_i, axis=1, batch_dims=0)\n",
        "                            z_y = tf.gather(y_pred, i_y_true, axis=1, batch_dims=0)\n",
        "\n",
        "                            z_1 = tf.linalg.diag_part(z_1)\n",
        "                            z_3 = tf.linalg.diag_part(z_3)\n",
        "                            z_i = tf.linalg.diag_part(z_i)\n",
        "                            z_y = tf.linalg.diag_part(z_y)\n",
        "\n",
        "                            dlr = -(z_y - z_i) / (z_1 - z_3)\n",
        "\n",
        "                            return tf.reduce_mean(dlr)\n",
        "\n",
        "                    self._loss_fn = DifferenceLogitsRatioTensorFlowV2()\n",
        "                    self._loss_object = DifferenceLogitsRatioTensorFlowV2()\n",
        "\n",
        "                estimator_apgd = TensorFlowV2Classifier(\n",
        "                    model=estimator.model,\n",
        "                    nb_classes=estimator.nb_classes,\n",
        "                    input_shape=estimator.input_shape,\n",
        "                    loss_object=self._loss_object,\n",
        "                    train_step=estimator._train_step,\n",
        "                    channels_first=estimator.channels_first,\n",
        "                    clip_values=estimator.clip_values,\n",
        "                    preprocessing_defences=estimator.preprocessing_defences,\n",
        "                    postprocessing_defences=estimator.postprocessing_defences,\n",
        "                    preprocessing=estimator.preprocessing,\n",
        "                )\n",
        "            elif isinstance(estimator, PyTorchClassifier):\n",
        "                import torch\n",
        "\n",
        "                if loss_type == \"cross_entropy\":\n",
        "                    if is_probability(\n",
        "                        estimator.predict(x=np.ones(shape=(1, *estimator.input_shape), dtype=np.float32))\n",
        "                    ):\n",
        "                        raise ValueError(\n",
        "                            \"The provided estimator seems to predict probabilities. If loss_type='cross_entropy' \"\n",
        "                            \"the estimator has to to predict logits.\"\n",
        "                        )\n",
        "\n",
        "                    self._loss_object = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "                elif loss_type == \"difference_logits_ratio\":\n",
        "                    if is_probability(\n",
        "                        estimator.predict(x=np.ones(shape=(1, *estimator.input_shape), dtype=ART_NUMPY_DTYPE))\n",
        "                    ):\n",
        "                        raise ValueError(\n",
        "                            \"The provided estimator seems to predict probabilities. \"\n",
        "                            \"If loss_type='difference_logits_ratio' the estimator has to to predict logits.\"\n",
        "                        )\n",
        "\n",
        "                    class DifferenceLogitsRatioPyTorch:\n",
        "                        \"\"\"\n",
        "                        Callable class for Difference Logits Ratio loss in PyTorch.\n",
        "                        \"\"\"\n",
        "\n",
        "                        def __init__(self):\n",
        "                            self.reduction = \"mean\"\n",
        "\n",
        "                        def __call__(self, y_pred, y_true):  # type: ignore\n",
        "                            if isinstance(y_true, np.ndarray):\n",
        "                                y_true = torch.from_numpy(y_true)\n",
        "                            if isinstance(y_pred, np.ndarray):\n",
        "                                y_pred = torch.from_numpy(y_pred)\n",
        "\n",
        "                            y_true = y_true.float()\n",
        "\n",
        "                            i_y_true = torch.argmax(y_true, axis=1)\n",
        "                            i_y_pred_arg = torch.argsort(y_pred, axis=1)\n",
        "                            i_z_i_list = list()\n",
        "\n",
        "                            for i in range(y_true.shape[0]):\n",
        "                                if i_y_pred_arg[i, -1] != i_y_true[i]:\n",
        "                                    i_z_i_list.append(i_y_pred_arg[i, -1])\n",
        "                                else:\n",
        "                                    i_z_i_list.append(i_y_pred_arg[i, -2])\n",
        "\n",
        "                            i_z_i = torch.stack(i_z_i_list)\n",
        "\n",
        "                            z_1 = y_pred[:, i_y_pred_arg[:, -1]]\n",
        "                            z_3 = y_pred[:, i_y_pred_arg[:, -3]]\n",
        "                            z_i = y_pred[:, i_z_i]\n",
        "                            z_y = y_pred[:, i_y_true]\n",
        "\n",
        "                            z_1 = torch.diagonal(z_1)\n",
        "                            z_3 = torch.diagonal(z_3)\n",
        "                            z_i = torch.diagonal(z_i)\n",
        "                            z_y = torch.diagonal(z_y)\n",
        "\n",
        "                            dlr = -(z_y - z_i) / (z_1 - z_3)\n",
        "\n",
        "                            return torch.mean(dlr.float())\n",
        "\n",
        "                    self._loss_object = DifferenceLogitsRatioPyTorch()\n",
        "\n",
        "                estimator_apgd = PyTorchClassifier(\n",
        "                    model=estimator.model,\n",
        "                    loss=self._loss_object,\n",
        "                    input_shape=estimator.input_shape,\n",
        "                    nb_classes=estimator.nb_classes,\n",
        "                    optimizer=None,\n",
        "                    channels_first=estimator.channels_first,\n",
        "                    clip_values=estimator.clip_values,\n",
        "                    preprocessing_defences=estimator.preprocessing_defences,\n",
        "                    postprocessing_defences=estimator.postprocessing_defences,\n",
        "                    preprocessing=estimator.preprocessing,\n",
        "                    device_type=str(estimator._device),\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"The loss type {} is not supported for the provided estimator.\".format(loss_type))\n",
        "\n",
        "        super().__init__(estimator=estimator_apgd)\n",
        "        self.norm = norm\n",
        "        self.eps = eps\n",
        "        self.eps_step = eps_step\n",
        "        self.max_iter = max_iter\n",
        "        self.targeted = targeted\n",
        "        self.nb_random_init = nb_random_init\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_type = loss_type\n",
        "        self.verbose = verbose\n",
        "        self._check_params()\n",
        "\n",
        "    def generate(self, x: np.ndarray, y: Optional[np.ndarray] = None, class_target=0, confidence=0.6, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate adversarial samples and return them in an array.\n",
        "        :param x: An array with the original inputs.\n",
        "        :param y: Target values (class labels) one-hot-encoded of shape `(nb_samples, nb_classes)` or indices of shape\n",
        "                  (nb_samples,). Only provide this parameter if you'd like to use true labels when crafting adversarial\n",
        "                  samples. Otherwise, model predictions are used as labels to avoid the \"label leaking\" effect\n",
        "                  (explained in this paper: https://arxiv.org/abs/1611.01236). Default is `None`.\n",
        "        :param mask: An array with a mask broadcastable to input `x` defining where to apply adversarial perturbations.\n",
        "                     Shape needs to be broadcastable to the shape of x and can also be of the same shape as `x`. Any\n",
        "                     features for which the mask is zero will not be adversarially perturbed.\n",
        "        :type mask: `np.ndarray`\n",
        "        :return: An array holding the adversarial examples.\n",
        "        \"\"\"\n",
        "        mask = kwargs.get(\"mask\")\n",
        "\n",
        "        y = check_and_transform_label_format(y, self.estimator.nb_classes)\n",
        "\n",
        "        if y is None:\n",
        "            if self.targeted:\n",
        "                raise ValueError(\"Target labels `y` need to be provided for a targeted attack.\")\n",
        "            y = get_labels_np_array(self.estimator.predict(x, batch_size=self.batch_size)).astype(np.int32)\n",
        "\n",
        "        if self.estimator.nb_classes == 2 and y.shape[1] == 1:\n",
        "            raise ValueError(\n",
        "                \"This attack has not yet been tested for binary classification with a single output classifier.\"\n",
        "            )\n",
        "\n",
        "        trans_prova= transforms.Compose([transforms.Resize([224,224],interpolation=InterpolationMode.NEAREST),\n",
        "                                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                                     ])\n",
        "        x_adv = x.astype(ART_NUMPY_DTYPE)\n",
        "        x=trans_prova(torch.Tensor(x))\n",
        "        x=np.array(x.numpy())\n",
        "        \n",
        "        for _ in trange(max(1, self.nb_random_init), desc=\"AutoPGD - restart\", disable=not self.verbose):\n",
        "            \n",
        "            # Determine correctly predicted samples\n",
        "            #y_pred = self.estimator.predict(x_adv)\n",
        "            \n",
        "            preds,value=test_average_preds(self.estimator,array2dataloader(x_adv,y)) #preds è già la classe finale mentre y_pred contiene i due valori\n",
        "            \n",
        "            if self.targeted:\n",
        "                sample_is_robust = np.argmax(y_pred, axis=1) != np.argmax(y, axis=1)\n",
        "            elif not self.targeted:\n",
        "                #sample_is_robust = np.argmax(y_pred, axis=1) == np.argmax(y, axis=1)\n",
        "                if ((preds==np.argmax(y, axis=1)) and (preds!= class_target)):\n",
        "                  sample_is_robust=True\n",
        "                elif ((preds!=np.argmax(y, axis=1)) and (preds== class_target) and (value<confidence)):  \n",
        "                  sample_is_robust=True\n",
        "                else:  sample_is_robust=False\n",
        "\n",
        "                #print(\"preds=label e preds=spoof\")\n",
        "              \n",
        "              \n",
        "                #print(\"preds=label, preds=live e confidence<0.6\")\n",
        "                \n",
        "              \n",
        "\n",
        "            #sample_is_robust è vettore di booleani, indica se l'attacco deve essere eseguito (True), ovvero se il modello predice bene\n",
        "            \n",
        "            #print(\"y: \"+str(y))\n",
        "            #print(\"pred: \"+str(preds))\n",
        "            #print(\"sampleisrobust: \"+str(sample_is_robust))\n",
        "            \n",
        "            if sample_is_robust == False:\n",
        "                break\n",
        "            \n",
        "            \n",
        "            x_adv=trans_prova(torch.Tensor(x_adv))\n",
        "            x_adv=np.array(x_adv.numpy())\n",
        "\n",
        "            x_robust = x_adv\n",
        "            y_robust = y\n",
        "            x_init = x\n",
        "            \n",
        "            n = x_robust.shape[0]\n",
        "            m = np.prod(x_robust.shape[1:]).item()\n",
        "            random_perturbation = (\n",
        "                random_sphere(n, m, self.eps, self.norm).reshape(x_robust.shape).astype(ART_NUMPY_DTYPE)\n",
        "            )\n",
        "\n",
        "            x_robust = x_robust + random_perturbation\n",
        "\n",
        "            if self.estimator.clip_values is not None:\n",
        "                clip_min, clip_max = self.estimator.clip_values\n",
        "                x_robust = np.clip(x_robust, clip_min, clip_max)\n",
        "\n",
        "            perturbation = projection(x_robust - x_init, self.eps, self.norm)\n",
        "            x_robust = x_init + perturbation\n",
        "\n",
        "            # Compute perturbation with implicit batching\n",
        "            for batch_id in trange(\n",
        "                int(np.ceil(x_robust.shape[0] / float(self.batch_size))),\n",
        "                desc=\"AutoPGD - batch\",\n",
        "                leave=False,\n",
        "                disable=not self.verbose,\n",
        "            ):\n",
        "                self.eta = 2 * self.eps_step\n",
        "                batch_index_1, batch_index_2 = batch_id * self.batch_size, (batch_id + 1) * self.batch_size\n",
        "                x_k = x_robust[batch_index_1:batch_index_2].astype(ART_NUMPY_DTYPE)\n",
        "                x_init_batch = x_init[batch_index_1:batch_index_2].astype(ART_NUMPY_DTYPE)\n",
        "                y_batch = y_robust[batch_index_1:batch_index_2]\n",
        "\n",
        "                p_0 = 0\n",
        "                p_1 = 0.22\n",
        "                var_w = [p_0, p_1]\n",
        "\n",
        "                while True:\n",
        "                    p_j_p_1 = var_w[-1] + max(var_w[-1] - var_w[-2] - 0.03, 0.06)\n",
        "                    if p_j_p_1 > 1:\n",
        "                        break\n",
        "                    var_w.append(p_j_p_1)\n",
        "\n",
        "                var_w = [math.ceil(p * self.max_iter) for p in var_w]\n",
        "\n",
        "                eta = self.eps_step\n",
        "                self.count_condition_1 = 0\n",
        "\n",
        "                for k_iter in trange(self.max_iter, desc=\"AutoPGD - iteration\", leave=False, disable=not self.verbose):\n",
        "\n",
        "                    # Get perturbation, use small scalar to avoid division by 0\n",
        "                    tol = 10e-8\n",
        "\n",
        "                    # Get gradient wrt loss; invert it if attack is targeted\n",
        "                    grad = self.estimator.loss_gradient(x_k, y_batch) * (1 - 2 * int(self.targeted))\n",
        "\n",
        "                    # Apply norm bound\n",
        "                    if self.norm in [np.inf, \"inf\"]:\n",
        "                        grad = np.sign(grad)\n",
        "                    elif self.norm == 1:\n",
        "                        ind = tuple(range(1, len(x_k.shape)))\n",
        "                        grad = grad / (np.sum(np.abs(grad), axis=ind, keepdims=True) + tol)\n",
        "                    elif self.norm == 2:\n",
        "                        ind = tuple(range(1, len(x_k.shape)))\n",
        "                        grad = grad / (np.sqrt(np.sum(np.square(grad), axis=ind, keepdims=True)) + tol)\n",
        "                    assert x_k.shape == grad.shape\n",
        "\n",
        "                    perturbation = grad\n",
        "\n",
        "                    if mask is not None:\n",
        "                        perturbation = perturbation * (mask.astype(ART_NUMPY_DTYPE))\n",
        "\n",
        "                    # Apply perturbation and clip\n",
        "                    z_k_p_1 = x_k + eta * perturbation\n",
        "\n",
        "                    if self.estimator.clip_values is not None:\n",
        "                        clip_min, clip_max = self.estimator.clip_values\n",
        "                        z_k_p_1 = np.clip(z_k_p_1, clip_min, clip_max)\n",
        "\n",
        "                    if k_iter == 0:\n",
        "                        x_1 = z_k_p_1\n",
        "                        perturbation = projection(x_1 - x_init_batch, self.eps, self.norm)\n",
        "                        x_1 = x_init_batch + perturbation\n",
        "\n",
        "                        f_0 = self.estimator.compute_loss(x=x_k, y=y_batch, reduction=\"mean\")\n",
        "                        f_1 = self.estimator.compute_loss(x=x_1, y=y_batch, reduction=\"mean\")\n",
        "\n",
        "                        self.eta_w_j_m_1 = eta\n",
        "                        self.f_max_w_j_m_1 = f_0\n",
        "\n",
        "                        if f_1 >= f_0:\n",
        "                            self.f_max = f_1\n",
        "                            self.x_max = x_1\n",
        "                            self.x_max_m_1 = x_init_batch\n",
        "                            self.count_condition_1 += 1\n",
        "                        else:\n",
        "                            self.f_max = f_0\n",
        "                            self.x_max = x_k.copy()\n",
        "                            self.x_max_m_1 = x_init_batch\n",
        "\n",
        "                        # Settings for next iteration k\n",
        "                        x_k_m_1 = x_k.copy()\n",
        "                        x_k = x_1\n",
        "\n",
        "                    else:\n",
        "                        perturbation = projection(z_k_p_1 - x_init_batch, self.eps, self.norm)\n",
        "                        z_k_p_1 = x_init_batch + perturbation\n",
        "\n",
        "                        alpha = 0.75\n",
        "\n",
        "                        x_k_p_1 = x_k + alpha * (z_k_p_1 - x_k) + (1 - alpha) * (x_k - x_k_m_1)\n",
        "\n",
        "                        if self.estimator.clip_values is not None:\n",
        "                            clip_min, clip_max = self.estimator.clip_values\n",
        "                            x_k_p_1 = np.clip(x_k_p_1, clip_min, clip_max)\n",
        "\n",
        "                        perturbation = projection(x_k_p_1 - x_init_batch, self.eps, self.norm)\n",
        "                        x_k_p_1 = x_init_batch + perturbation\n",
        "\n",
        "                        f_k_p_1 = self.estimator.compute_loss(x=x_k_p_1, y=y_batch, reduction=\"mean\")\n",
        "\n",
        "                        if f_k_p_1 == 0.0:\n",
        "                            x_k = x_k_p_1.copy()\n",
        "                            break\n",
        "\n",
        "                        if (not self.targeted and f_k_p_1 > self.f_max) or (self.targeted and f_k_p_1 < self.f_max):\n",
        "                            self.count_condition_1 += 1\n",
        "                            self.x_max = x_k_p_1\n",
        "                            self.x_max_m_1 = x_k\n",
        "                            self.f_max = f_k_p_1\n",
        "\n",
        "                        if k_iter in var_w:\n",
        "\n",
        "                            rho = 0.75\n",
        "\n",
        "                            condition_1 = self.count_condition_1 < rho * (k_iter - var_w[var_w.index(k_iter) - 1])\n",
        "                            condition_2 = self.eta_w_j_m_1 == eta and self.f_max_w_j_m_1 == self.f_max\n",
        "\n",
        "                            if condition_1 or condition_2:\n",
        "                                eta = eta / 2\n",
        "                                x_k_m_1 = self.x_max_m_1\n",
        "                                x_k = self.x_max\n",
        "                            else:\n",
        "                                x_k_m_1 = x_k\n",
        "                                x_k = x_k_p_1.copy()\n",
        "\n",
        "                            self.count_condition_1 = 0\n",
        "                            self.eta_w_j_m_1 = eta\n",
        "                            self.f_max_w_j_m_1 = self.f_max\n",
        "\n",
        "                        else:\n",
        "                            x_k_m_1 = x_k\n",
        "                            x_k = x_k_p_1.copy()\n",
        "\n",
        "                preds,value=test_average_preds(self.estimator,array2dataloader(x_k,y_batch))\n",
        "                #y_pred_adv_k = self.estimator.predict(x_k)\n",
        "                if self.targeted:\n",
        "                    sample_is_not_robust_k = np.invert(np.argmax(y_pred_adv_k, axis=1) != np.argmax(y_batch, axis=1))\n",
        "                elif not self.targeted:\n",
        "                    #sample_is_not_robust_k = np.invert(preds == np.argmax(y_batch, axis=1))\n",
        "                    if ((preds==np.argmax(y, axis=1)) and (preds!= class_target)):\n",
        "                      sample_is_not_robust=False\n",
        "                    elif ((preds!=np.argmax(y, axis=1)) and (preds== class_target) and (value<confidence)):  \n",
        "                      sample_is_not_robust=False\n",
        "                    else:  sample_is_not_robust=True\n",
        "\n",
        "                if sample_is_not_robust:\n",
        "                  x_robust[batch_index_1:batch_index_2] = x_k #carica x_robust con x_k solo se preds!=label\n",
        "\n",
        "            x_adv = x_robust\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "    def _check_params(self) -> None:\n",
        "        if self.norm not in [1, 2, np.inf, \"inf\"]:\n",
        "            raise ValueError('The argument norm has to be either 1, 2, np.inf, or \"inf\".')\n",
        "\n",
        "        if not isinstance(self.eps, (int, float)) or self.eps <= 0.0:\n",
        "            raise ValueError(\"The argument eps has to be either of type int or float and larger than zero.\")\n",
        "\n",
        "        if not isinstance(self.eps_step, (int, float)) or self.eps_step <= 0.0:\n",
        "            raise ValueError(\"The argument eps_step has to be either of type int or float and larger than zero.\")\n",
        "\n",
        "        if not isinstance(self.max_iter, int) or self.max_iter <= 0:\n",
        "            raise ValueError(\"The argument max_iter has to be of type int and larger than zero.\")\n",
        "\n",
        "        if not isinstance(self.targeted, bool):\n",
        "            raise ValueError(\"The argument targeted has to be of bool.\")\n",
        "\n",
        "        if not isinstance(self.nb_random_init, int) or self.nb_random_init <= 0:\n",
        "            raise ValueError(\"The argument nb_random_init has to be of type int and larger than zero.\")\n",
        "\n",
        "        if not isinstance(self.batch_size, int) or self.batch_size <= 0:\n",
        "            raise ValueError(\"The argument batch_size has to be of type int and larger than zero.\")\n",
        "\n",
        "        if self.loss_type not in self._predefined_losses:\n",
        "            raise ValueError(\"The argument loss_type has to be either {}.\".format(self._predefined_losses))\n",
        "\n",
        "        if not isinstance(self.verbose, bool):\n",
        "            raise ValueError(\"The argument `verbose` has to be of type bool.\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2z5CDqCOjhi"
      },
      "source": [
        "# **Esecuzione**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzZkC7HimlHT"
      },
      "source": [
        "##Creazione classificatore ART Pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZL7c94zmlHU"
      },
      "source": [
        "from art.estimators.classification import PyTorchClassifier\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(0, 1),\n",
        "    loss=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.Adam(model.classifier.parameters(),lr=1e-5),\n",
        "    input_shape=(3, 224, 224),\n",
        "    nb_classes=class_number\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m10EkCq5GeEu"
      },
      "source": [
        "##Attacco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6HHOwTUIKKO"
      },
      "source": [
        "###Def attacco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocv1IPUJIMts"
      },
      "source": [
        "attack = AutoProjectedGradientDescent_mod(classifier,eps=10000,eps_step=0.1,nb_random_init=5,max_iter=100,verbose=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PG4U0TJb6Qj"
      },
      "source": [
        "###Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yk7RwELGfM4",
        "outputId": "f4f593ea-dca3-4ddd-dec1-bc985a17373b"
      },
      "source": [
        "from art.utils import to_categorical\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#x_test_adv=[] \n",
        "#y_test_adv=[] \n",
        "Test_p = pd.DataFrame()\n",
        "model.eval()\n",
        "model.cuda()\n",
        "prob=nn.Softmax()\n",
        "data_transform_test= transforms.Compose([transforms.Resize([224,224],interpolation=InterpolationMode.NEAREST),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])\n",
        "i=0\n",
        "for input,label in testgen:\n",
        "  i+=1\n",
        "\n",
        "  sys.stdout.write(\"\\rElem: {0}/{1}\".format(i,len(testgen)))\n",
        "  sys.stdout.flush()\n",
        "  \n",
        "  #input=data_transform_test(input) #prima faccio resize a 224 per calcolare le adv\n",
        "\n",
        "  y_test=np.array((to_categorical(label.numpy(),2)))\n",
        "  x_test=np.array(input.numpy())\n",
        "  \n",
        "  x_test_adv=attack.generate(x=x_test,y=y_test,class_target=classes_name.index('Live'),confidence=0.6)[0,:,:,:]\n",
        "\n",
        "  x_test_adv=torch.Tensor(x_test_adv)\n",
        "  x_test_adv=x_test_adv.unsqueeze_(0)\n",
        "  if x_test_adv.shape[2]!=1000:\n",
        "    x_test_adv=transf_init(x_test_adv) #faccio resize adv a 1000 per calcolare le patch\n",
        "\n",
        "  n=x_test_adv.shape\n",
        "  n_mod=calc_size(n[2:4])\n",
        "  crop_transform=transforms.TenCrop((n_mod[0],n_mod[1])).to(device)\n",
        "  crops=crop_transform(x_test_adv)\n",
        "  live=0\n",
        "  spoof=0\n",
        "  for crop in crops:\n",
        "    crop=data_transform_test(crop).to(device) #per ogni patch viene faccio il resize a 224 per il testing\n",
        "    outputs = model(crop)\n",
        "    live+=outputs[0][0]\n",
        "    spoof+=outputs[0][1]\n",
        "  live=live/10\n",
        "  spoof=spoof/10\n",
        "  probabilities=prob(torch.Tensor([live,spoof])).numpy()\n",
        "  Test_p = Test_p.append({'real': classes_name[int(label)] ,\n",
        "                          'predicted': classes_name[np.argmax([live,spoof])],\n",
        "                          'prob_live': round(probabilities[0],4),\n",
        "                          'prob_spoof': round(probabilities[1],4)},ignore_index = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elem: 2/2500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elem: 748/2500"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFKEoI-enb8L"
      },
      "source": [
        "##Testing\n",
        "\n",
        "> Trasforma i due testing in una funzione e richiamala due volte\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MmzfXhFt40W"
      },
      "source": [
        "###Print accuracy test orig from file & load pd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSOr1z85vhl7"
      },
      "source": [
        "Test_orig=pd.read_excel(pd_preds_value)\n",
        "true_label = Test_orig.real.values\n",
        "predicted = Test_orig.predicted.values\n",
        "accuracy=round((np.sum((true_label == predicted).astype(int)))/Test_orig.shape[0],4)*100\n",
        "print(\"\\nAccuracy: {0}\".format(accuracy))\n",
        "print(\"Shape dataframe: {0}\".format(Test_orig.shape))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQwAjZgDcj-P"
      },
      "source": [
        "###Calcola accuracy testset originale (da usare con dataset ridotto per confronto con adv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3IsDD1Ka-UN"
      },
      "source": [
        "def test_average(model,test_loader,):\n",
        "  '''\n",
        "  model: model trained\n",
        "  test_loader: dataloader \n",
        "  return: dataframe{n_img,class_predicted,class_real}\n",
        "  '''\n",
        "\n",
        "  Test = pd.DataFrame()\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "  data_transform_test= transforms.Compose([transforms.Resize([224,224]),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "          ])\n",
        "  i=0\n",
        "  for input,label in test_loader:\n",
        "    i+=1\n",
        "    n=input.shape\n",
        "    n_mod=calc_size(n[2:4])\n",
        "    crop_transform=transforms.TenCrop((n_mod[0],n_mod[1])).to(device)\n",
        "    crops=crop_transform(input)\n",
        "    live=0\n",
        "    spoof=0\n",
        "    sys.stdout.write(\"\\rImage {0}/{1}\".format(i,len(test_loader)))\n",
        "    sys.stdout.flush()\n",
        "    for crop in crops:\n",
        "      crop=data_transform_test(crop).to(device)\n",
        "      outputs = model(crop)\n",
        "      live+=outputs[0][0]\n",
        "      spoof+=outputs[0][1]\n",
        "    live=live/10\n",
        "    spoof=spoof/10\n",
        "    predicted=np.argmax([live,spoof])\n",
        "    Test = Test.append({'real': classes_name[int(label)] ,\n",
        "                        'predicted': classes_name[predicted],\n",
        "                        'value_pred_live': live.item(),\n",
        "                        'value_pred_spoof': spoof.item()},ignore_index = True)\n",
        "\n",
        "  true_label = Test.real.values\n",
        "  predicted = Test.predicted.values\n",
        "  accuracy=round((np.sum((true_label == predicted).astype(int)))/Test.shape[0],4)*100\n",
        "  print(\"\\nAccuracy: {0}\".format(accuracy))\n",
        "  print(\"Shape dataframe: {0}\".format(Test.shape))  \n",
        "\n",
        "  return Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF708OvcbLjs",
        "outputId": "d3b9b22e-93ec-4b8d-e3e7-8ca906c4389e"
      },
      "source": [
        "Test_orig=test_average(model,testgen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 5/5\n",
            "Accuracy: 60.0\n",
            "Shape dataframe: (5, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmjrhHYsVsN"
      },
      "source": [
        "###Testing immagini spoof predette live prima e dopo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH268rz8axWg"
      },
      "source": [
        "print(Test_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGuElPEOW3dZ"
      },
      "source": [
        "####Accuracy adv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp0jAIC-W5zC"
      },
      "source": [
        "true_label = Test_p.real.values\n",
        "predicted = Test_p.predicted.values\n",
        "accuracy=round((np.sum((true_label == predicted).astype(int)))/Test_p.shape[0],4)*100\n",
        "print(\"\\nAccuracy: {0}\".format(accuracy))\n",
        "print(\"Shape dataframe: {0}\".format(Test_p.shape)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyLoc2K6V_ar"
      },
      "source": [
        "####Spoof"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZwQC-osvGM"
      },
      "source": [
        "print(Test_orig)\n",
        "n_spoof=np.sum(Test_orig['real']=='Spoof')\n",
        "print(\"# img spoof: \"+str(n_spoof))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0SfSelFK2dl"
      },
      "source": [
        "prima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsNqIDAxsZBA"
      },
      "source": [
        "p=Test_orig.loc[Test_orig['real']=='Spoof']\n",
        "p1=p.loc[p['predicted']==p['real']]\n",
        "print(\"Img realmente spoof e predette spoof\")\n",
        "print(p1)\n",
        "n_spoof_pred=p1.count(0)[0]\n",
        "print(\"Numero di predizioni spoof giuste: \"+str(n_spoof_pred))\n",
        "print(\"Accuracy su img spoof: \"+str(round(n_spoof_pred/n_spoof*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AciVwgFyK3Xc"
      },
      "source": [
        "dopo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2xU5gUQuy7y"
      },
      "source": [
        "d=Test_p.loc[Test_p['real']=='Spoof']\n",
        "d1=d.loc[d['predicted']==d['real']]\n",
        "print(\"Img realmente spoof e predette spoof\")\n",
        "print(d1)\n",
        "n_spoof_pred2=d1.count(0)[0]\n",
        "print(\"Numero di predizioni spoof giuste: \"+str(n_spoof_pred2))\n",
        "print(\"Accuracy su img spoof: \"+str(round(n_spoof_pred2/n_spoof*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Q78IIqWCTI"
      },
      "source": [
        "####Live"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuxOWBYWTLk"
      },
      "source": [
        "print(Test_orig)\n",
        "n_live=np.sum(Test_orig['real']=='Live')\n",
        "print(\"# img live: \"+str(n_live))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtPKGqzEWCTI"
      },
      "source": [
        "prima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtB5Te35WCTJ"
      },
      "source": [
        "p=Test_orig.loc[Test_orig['real']=='Live']\n",
        "p1=p.loc[p['predicted']==p['real']]\n",
        "print(\"Img realmente live e predette live\")\n",
        "print(p1)\n",
        "n_live_pred=p1.count(0)[0]\n",
        "print(\"Numero di predizioni live giuste: \"+str(n_live_pred))\n",
        "print(\"Accuracy su img live: \"+str(round(n_live_pred/n_live*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3VNm1BCWCTJ"
      },
      "source": [
        "dopo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssG-LK1zWCTJ"
      },
      "source": [
        "d=Test_p.loc[Test_p['real']=='Live']\n",
        "d1=d.loc[d['predicted']==d['real']]\n",
        "print(\"Img realmente live e predette live\")\n",
        "print(d1)\n",
        "n_live_pred2=d1.count(0)[0]\n",
        "print(\"Numero di predizioni live giuste: \"+str(n_live_pred2))\n",
        "print(\"Accuracy su img live: \"+str(round(n_live_pred2/n_live*100,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBRYj9D8kFE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test_adv[0].numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}