{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Addestramento_scanner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJ9lTpb5yVnD/kPH4CE/4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/Tesi/blob/main/Impronte/Addestramento_scanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoLiAGAtqBh"
      },
      "source": [
        "# **Init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "## Import librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8Xcxz3A2h_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "##Def variabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#Scanner\n",
        "scanner_name = 'DigitalPersona'\n",
        "\n",
        "#salvataggio modello\n",
        "model_save_name = 'VGG16'\n",
        "path_model_save = F\"/content/gdrive/My Drive/ModelliCNN/Scanner/{scanner_name}/{model_save_name}\" \n",
        "\n",
        "#load dataset training\n",
        "pathDataset=F'/content/gdrive/MyDrive/Dataset_impronte/training/{scanner_name}'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXZpnFgqg61P"
      },
      "source": [
        "##Parametri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8E_NSHHg8JZ"
      },
      "source": [
        "batch_size=128\n",
        "num_class=2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "##Collegamento google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvTOQw-aHRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39224d2a-e0cb-47db-a583-999c45ebcdad"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4b2eLxnouZ8"
      },
      "source": [
        "##Caricamento dataset pytorch (elimina)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS-Uzs8BjD4R"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "\n",
        "data_transform=transforms.Compose([transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(pathDataset,transform=data_transform,)\n",
        "\n",
        "train_size = int(len(train_dataset) * 0.8)\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "#splitter = DatasetValidationSplitter(len(trainset), 0.2)\n",
        "#trainset_split = splitter.get_train_dataset(trainset)\n",
        "#valset = splitter.get_val_dataset(trainset)\n",
        "\n",
        "traingen = torch.utils.data.DataLoader(train_set, pin_memory=True, batch_size=batch_size, shuffle=True,num_workers=2)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4OZij1RgOON"
      },
      "source": [
        "###Riduzione dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAV-L9s3jfIN"
      },
      "source": [
        "#riduzione train set\n",
        "trainset.data=trainset.data[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4hHndtkosDV"
      },
      "source": [
        "###Stampa dimensioni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZBAfQHAoHKk"
      },
      "source": [
        "print(\"Dimensione trainset_split: \"+str(len(trainset_split)))\n",
        "print(\"Dimensione valset: \"+str(len(valset)))\n",
        "print(\"Dimensione testset: \"+str(len(testset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazQQE8ypKP9"
      },
      "source": [
        "###Nomi classi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYk4cr4eo9Ir"
      },
      "source": [
        "classes_name=trainset.classes\n",
        "class_number=len(classes_name)\n",
        "print(classes_name)\n",
        "print(class_number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5zWPr28gZrE"
      },
      "source": [
        "##Caricamento dataset tensorflow (elimina)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lNeErf4gb2_",
        "outputId": "ac689f26-7382-47c1-ab40-60276895a618"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
        "    pathDataset,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical')\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  pathDataset,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  batch_size=batch_size,\n",
        "  label_mode='categorical')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2500 files belonging to 2 classes.\n",
            "Using 2000 files for training.\n",
            "Found 2500 files belonging to 2 classes.\n",
            "Using 500 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAgLpxHkp5n"
      },
      "source": [
        "###Classi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzxdEdVPks5B",
        "outputId": "bb912e78-314c-4334-eab0-ae02169328e7"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Live', 'Spoof']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae09d3OthN5z"
      },
      "source": [
        "###stampa immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxn9kPCMhPnV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku4C3tKkk9UY"
      },
      "source": [
        "###Stampa info dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGxF2Demk-94",
        "outputId": "219bced8-1bbf-43e6-e2e4-0140b9ceffc2"
      },
      "source": [
        "print(len(train_ds)) #numero batch di dimensione 128"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW49svoRwX67"
      },
      "source": [
        "###Stampa info singolo elemento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzdtDXiwx3sf"
      },
      "source": [
        "train_iter=iter(train_ds)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDpjdkDnx7iH"
      },
      "source": [
        "image_batch, labels_batch = next(train_iter)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWgD0yU5jRj"
      },
      "source": [
        "print(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtzlIhngw9e3",
        "outputId": "341154b4-965f-4313-e843-4893ac474688"
      },
      "source": [
        "print(image_batch[0].shape)\n",
        "print(labels_batch[:5])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n",
            "tf.Tensor(\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]], shape=(5, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58A99jDizASL"
      },
      "source": [
        "im_shape=image_batch[0].shape"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSyijWDqY4-"
      },
      "source": [
        "###Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GymaBXhaPMvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2984220-15ad-461a-983d-c5ff0d23f113"
      },
      "source": [
        "#creazione rete usando vgg16 preaddestrata e aggiungendo gli ultimi livelli per adattarla al problema di 10 classi\n",
        "from tensorflow.keras import applications as applications\n",
        "\n",
        "#importa rete vgg16 addestrata sul dataset imagenet, esclude gli ultimi livelli e come input pongo dimensioni 96,96,3 \n",
        "model_conv = applications.VGG16(weights='imagenet', include_top=False, input_shape=(im_shape[0],im_shape[1],im_shape[2]))\n",
        "\n",
        "# Freeze all the layers (non modifico i pesi dei livelli inferiori)\n",
        "for layer in model_conv.layers[:]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkxmNsf41B6Y"
      },
      "source": [
        "###training\n",
        "> per riaddestrare eseguire solo questa sezione\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyBgJAA6zJcI"
      },
      "source": [
        "####Aggiunta classificatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h_fBDmpzFa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df255a1-6c3a-4d5c-933f-b5e20768c137"
      },
      "source": [
        "from tensorflow.keras import layers,models,losses,optimizers,applications\n",
        "import numpy as np\n",
        "\n",
        "# creo un modello aggiungendo livelli alla rete importata\n",
        "model = models.Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "model.add(model_conv)\n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(2, activation='softmax')) #10: numero di valori in uscita (le classi)\n",
        "\n",
        "#stampa info del modello\n",
        "model.summary()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              33555456  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 48,272,194\n",
            "Trainable params: 33,557,506\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZko74RzzcCr"
      },
      "source": [
        "####Configura parametri modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfXtu3eazk5l"
      },
      "source": [
        "# Configure the model for training (setta i parametri del modello)\n",
        "model.compile(\n",
        "        loss=losses.categorical_crossentropy, optimizer=optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"]\n",
        "    )"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-b3YpaWznuq"
      },
      "source": [
        "####Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr5rYORYzNxu"
      },
      "source": [
        "history= model.fit(train_ds,epochs=5,validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23P2KUBX1tSl"
      },
      "source": [
        "##Caricamento dataset tensorflow 2 (def)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLEJyXKH-wCr"
      },
      "source": [
        "caricamento dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92g_xG051y1A",
        "outputId": "5c155f6a-2032-40bf-e80a-0557cc7bb313"
      },
      "source": [
        "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
        "    pathDataset,\n",
        "    label_mode='categorical')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqwvqHT6-scH"
      },
      "source": [
        "calcolo dimensioni dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyzLntS34TB"
      },
      "source": [
        "#cambia: usa conteggio file nella cartella per velocizzare\n",
        "dim_set=0\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  dim_set=dim_set+image_batch.get_shape()[0]\n",
        "print(dim_set)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUN_IwXM_NQf"
      },
      "source": [
        "calcolo dimensioni singola immagine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLV_aaYo-7zL"
      },
      "source": [
        "image_batch, labels_batch = next(iter(train_ds))\n",
        "im_shape=image_batch[0].shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbhQAO5K3zmh"
      },
      "source": [
        "x_train = np.zeros((dim_set, im_shape[0], im_shape[1], im_shape[2]), dtype=np.uint8)\n",
        "y_train = np.zeros((dim_set,num_class), dtype=np.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AY13zu68xkK",
        "outputId": "d0ad7060-c38a-4cf1-d059-8eb59486fbdb"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNpbXCQ3vhZ"
      },
      "source": [
        "i=0\n",
        "j=0\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  j=i+image_batch.get_shape()[0]\n",
        "  #print(\"i: \"+str(i))\n",
        "  #print(\"j: \"+str(j))\n",
        "  x_train[i : j,:,:,:]=image_batch\n",
        "  y_train[i : j ,:]=labels_batch\n",
        "  i=j\n",
        "\n",
        "del i,j  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08ytGsTAOLG"
      },
      "source": [
        "preprocessing immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8e84CdeAP7p"
      },
      "source": [
        "min_, max_ = np.amin(x_train), np.amax(x_train)\n",
        "x_train = (x_train - min_) / (max_ - min_)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3sNlma-EeI"
      },
      "source": [
        "###Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUTgpK_W-EeJ",
        "outputId": "8d279af9-b95e-4096-9525-c3427db34225"
      },
      "source": [
        "#creazione rete usando vgg16 preaddestrata e aggiungendo gli ultimi livelli per adattarla al problema di 10 classi\n",
        "from tensorflow.keras import applications as applications\n",
        "\n",
        "#importa rete vgg16 addestrata sul dataset imagenet, esclude gli ultimi livelli e come input pongo dimensioni 96,96,3 \n",
        "model_conv = applications.VGG16(weights='imagenet', include_top=False, input_shape=(im_shape[0],im_shape[1],im_shape[2]))\n",
        "\n",
        "# Freeze all the layers (non modifico i pesi dei livelli inferiori)\n",
        "for layer in model_conv.layers[:]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-btSjeyI-HYY"
      },
      "source": [
        "###training\n",
        "> per riaddestrare eseguire solo questa sezione\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WL3EWUC-HYY"
      },
      "source": [
        "####Aggiunta classificatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPJgztCf-HYY",
        "outputId": "d32b61f6-e2b6-49ea-e210-c91b6a195b15"
      },
      "source": [
        "from tensorflow.keras import layers,models,losses,optimizers,applications\n",
        "import numpy as np\n",
        "\n",
        "# creo un modello aggiungendo livelli alla rete importata\n",
        "model = models.Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "model.add(model_conv)\n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_class, activation='softmax')) #10: numero di valori in uscita (le classi)\n",
        "\n",
        "#stampa info del modello\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              33555456  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 48,272,194\n",
            "Trainable params: 33,557,506\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHJow7j0-HYZ"
      },
      "source": [
        "####Configura parametri modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6kUxnaC-HYZ"
      },
      "source": [
        "# Configure the model for training (setta i parametri del modello)\n",
        "model.compile(\n",
        "        loss=losses.categorical_crossentropy, optimizer=optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"]\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCu_rIMU-HYZ"
      },
      "source": [
        "####Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeYtRtVw-HYZ",
        "outputId": "5b36d0ee-a58c-4b90-b4b7-5c1930048106"
      },
      "source": [
        "history= model.fit(x_train,y_train,epochs=2,batch_size=128,validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "13/13 [==============================] - 103s 3s/step - loss: 1.0203 - accuracy: 0.6800 - val_loss: 0.3003 - val_accuracy: 0.8750\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 18s 1s/step - loss: 0.2667 - accuracy: 0.8856 - val_loss: 0.1748 - val_accuracy: 0.9300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFFWkmjX2j5P"
      },
      "source": [
        "#**Salvataggio modello**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAie77UO2nTs"
      },
      "source": [
        "#salva modello su drive\n",
        "model.save(path_model_save)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}