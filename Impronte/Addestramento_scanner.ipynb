{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Addestramento_scanner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjG8PIShwcHtKFsW2ZmFXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertogagl97/Tesi/blob/main/Impronte/Addestramento_scanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcoLiAGAtqBh"
      },
      "source": [
        "# **Init**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGmEBN4oxqUO"
      },
      "source": [
        "## Import librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8Xcxz3A2h_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ycpjmyb4Cxe"
      },
      "source": [
        "##Def variabili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMuySVI4GgY"
      },
      "source": [
        "#Scanner\n",
        "scanner_name = 'DigitalPersona'\n",
        "\n",
        "#salvataggio modello\n",
        "model_save_name = 'VGG19_first_trial'\n",
        "path_model_save = F\"/content/gdrive/My Drive/ModelliCNN/Scanner/{scanner_name}/{model_save_name}\" \n",
        "\n",
        "#load dataset training\n",
        "pathDataset=F'/content/gdrive/MyDrive/Dataset_impronte/training/{scanner_name}'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXZpnFgqg61P"
      },
      "source": [
        "##Parametri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8E_NSHHg8JZ"
      },
      "source": [
        "batch_size=128\n",
        "num_class=2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dherpFOH0Uau"
      },
      "source": [
        "##Collegamento google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyvTOQw-aHRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39224d2a-e0cb-47db-a583-999c45ebcdad"
      },
      "source": [
        "#collegamento google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X10jetEyAax"
      },
      "source": [
        "#**Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23P2KUBX1tSl"
      },
      "source": [
        "##Caricamento dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92g_xG051y1A",
        "outputId": "5c155f6a-2032-40bf-e80a-0557cc7bb313"
      },
      "source": [
        "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
        "    pathDataset,\n",
        "    label_mode='categorical')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqwvqHT6-scH"
      },
      "source": [
        "##Calcolo dimensioni dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyzLntS34TB"
      },
      "source": [
        "#cambia: usa conteggio file nella cartella per velocizzare\n",
        "dim_set=0\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  dim_set=dim_set+image_batch.get_shape()[0]\n",
        "print(dim_set)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUN_IwXM_NQf"
      },
      "source": [
        "##Calcolo dimensioni immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLV_aaYo-7zL"
      },
      "source": [
        "image_batch, labels_batch = next(iter(train_ds))\n",
        "im_shape=image_batch[0].shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNizC8a9EM6c"
      },
      "source": [
        "##Creazione matrici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbhQAO5K3zmh"
      },
      "source": [
        "x_train = np.zeros((dim_set, im_shape[0], im_shape[1], im_shape[2]), dtype=np.uint8)\n",
        "y_train = np.zeros((dim_set,num_class), dtype=np.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AY13zu68xkK",
        "outputId": "d0ad7060-c38a-4cf1-d059-8eb59486fbdb"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNpbXCQ3vhZ"
      },
      "source": [
        "i=0\n",
        "j=0\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  j=i+image_batch.get_shape()[0]\n",
        "  #print(\"i: \"+str(i))\n",
        "  #print(\"j: \"+str(j))\n",
        "  x_train[i : j,:,:,:]=image_batch\n",
        "  y_train[i : j ,:]=labels_batch\n",
        "  i=j\n",
        "\n",
        "del i,j  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08ytGsTAOLG"
      },
      "source": [
        "##Preprocessing immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8e84CdeAP7p"
      },
      "source": [
        "min_, max_ = np.amin(x_train), np.amax(x_train)\n",
        "x_train = (x_train - min_) / (max_ - min_)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZIQY5cEWhQ"
      },
      "source": [
        "#**Creazione modello**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3sNlma-EeI"
      },
      "source": [
        "###Load model pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUTgpK_W-EeJ",
        "outputId": "a8875725-8b1e-4009-d5f8-d95d27c1a632"
      },
      "source": [
        "#creazione rete usando vgg16 preaddestrata e aggiungendo gli ultimi livelli per adattarla al problema di 10 classi\n",
        "from tensorflow.keras import applications as applications\n",
        "\n",
        "#importa rete vgg16 addestrata sul dataset imagenet, esclude gli ultimi livelli e come input pongo dimensioni 96,96,3 \n",
        "model_conv = applications.VGG19(weights='imagenet', include_top=False, input_shape=(im_shape[0],im_shape[1],im_shape[2]))\n",
        "\n",
        "# Freeze all the layers (non modifico i pesi dei livelli inferiori)\n",
        "for layer in model_conv.layers[:]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-btSjeyI-HYY"
      },
      "source": [
        "#**Training**\n",
        "> per riaddestrare eseguire solo questa sezione\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WL3EWUC-HYY"
      },
      "source": [
        "##Aggiunta classificatore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPJgztCf-HYY",
        "outputId": "7a58b729-fe8f-4e58-a4e3-5f22b339359e"
      },
      "source": [
        "from tensorflow.keras import layers,models,losses,optimizers,applications\n",
        "import numpy as np\n",
        "\n",
        "# creo un modello aggiungendo livelli alla rete importata\n",
        "model = models.Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "model.add(model_conv)\n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(num_class, activation='softmax')) #10: numero di valori in uscita (le classi)\n",
        "\n",
        "#stampa info del modello\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 8, 8, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              33555456  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 53,581,890\n",
            "Trainable params: 33,557,506\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHJow7j0-HYZ"
      },
      "source": [
        "##Configura parametri modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6kUxnaC-HYZ"
      },
      "source": [
        "# Configure the model for training (setta i parametri del modello)\n",
        "model.compile(\n",
        "        loss=losses.categorical_crossentropy, optimizer=optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"]\n",
        "    )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCu_rIMU-HYZ"
      },
      "source": [
        "##Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeYtRtVw-HYZ",
        "outputId": "613ddec2-c716-41b4-f526-9a0c505be81b"
      },
      "source": [
        "history= model.fit(x_train,y_train,epochs=10,batch_size=64)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 23s 675ms/step - loss: 0.6030 - accuracy: 0.6980\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 22s 674ms/step - loss: 0.2657 - accuracy: 0.9015\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 22s 674ms/step - loss: 0.1831 - accuracy: 0.9375\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 22s 673ms/step - loss: 0.1487 - accuracy: 0.9515\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 22s 674ms/step - loss: 0.1245 - accuracy: 0.9600\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 22s 672ms/step - loss: 0.1037 - accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 21s 671ms/step - loss: 0.0907 - accuracy: 0.9745\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 22s 678ms/step - loss: 0.0832 - accuracy: 0.9805\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 22s 678ms/step - loss: 0.0693 - accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 22s 678ms/step - loss: 0.0617 - accuracy: 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFFWkmjX2j5P"
      },
      "source": [
        "#**Salvataggio modello**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAie77UO2nTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4174d67e-96ea-49e7-b8a7-4120fdd98f93"
      },
      "source": [
        "#salva modello su drive\n",
        "model.save(path_model_save)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/ModelliCNN/Scanner/DigitalPersona/VGG19_first_trial/assets\n"
          ]
        }
      ]
    }
  ]
}